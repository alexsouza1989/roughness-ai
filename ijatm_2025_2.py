# -*- coding: utf-8 -*-
"""IJATM_2025_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12BgrmWU1Z4-R8xy1u7DzAXifzJtqg5vL
"""

# Instalar uma fonte similar à Times New Roman
!apt-get install -y fonts-liberation

# Configurar o matplotlib para usar a fonte Liberation Serif, que é similar à Times New Roman
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# Carregar a fonte instalada
font_path = '/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf'
fm.fontManager.addfont(font_path)
plt.rcParams['font.family'] = 'Liberation Serif'

import pandas as pd
import seaborn as sn

"""Primeiro: Vamos usar apenas a rugosidade e custo do processo"""

import pandas as pd

# Dados para CC6050
data_cc6050 = {
    "Vc": [100.00, 225.00, 100.00, 225.00, 100.00, 225.00, 100.00, 225.00, 57.39, 267.61,
           162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50],
    "f": [0.10, 0.10, 0.22, 0.22, 0.10, 0.10, 0.22, 0.22, 0.16, 0.16,
          0.05, 0.26, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16],
    "ap": [0.15, 0.15, 0.15, 0.15, 0.33, 0.33, 0.33, 0.33, 0.24, 0.24,
           0.24, 0.24, 0.09, 0.39, 0.24, 0.24, 0.24, 0.24, 0.24],
    "Ra": [0.62, 0.64, 0.98, 1.09, 0.65, 0.72, 1.33, 1.39, 1.12, 1.97,
           0.32, 1.35, 0.87, 0.95, 1.14, 1.13, 1.12, 1.14, 1.13],
    "Kp": [2.46, 1.52, 1.92, 1.25, 3.01, 1.76, 2.33, 1.12, 3.18, 1.18,
           2.76, 1.43, 1.45, 1.87, 1.87, 1.85, 1.89, 1.85, 1.83]
}
df_cc6050 = pd.DataFrame(data_cc6050)

# Dados para PCBN7025
data_pcbn7025 = {
    "Vc": [100.00, 225.00, 100.00, 225.00, 100.00, 225.00, 100.00, 225.00, 57.39, 267.61,
           162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50],
    "f": [0.10, 0.10, 0.22, 0.22, 0.10, 0.10, 0.22, 0.22, 0.16, 0.16,
          0.05, 0.26, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16],
    "ap": [0.15, 0.15, 0.15, 0.15, 0.33, 0.33, 0.33, 0.33, 0.24, 0.24,
           0.24, 0.24, 0.09, 0.39, 0.24, 0.24, 0.24, 0.24, 0.24],
    "Ra": [0.62, 0.64, 2.14, 2.15, 0.65, 0.62, 1.93, 2.39, 0.67, 1.17,
           0.31, 2.14, 1.20, 0.70, 0.81, 0.82, 0.83, 0.81, 0.83],
    "Kp": [3.66, 2.33, 3.47, 2.17, 5.20, 3.01, 4.61, 1.79, 5.51, 1.87,
           4.32, 2.58, 2.28, 3.46, 3.47, 3.42, 3.53, 3.41, 3.36]
}
df_pcbn7025 = pd.DataFrame(data_pcbn7025)

# Selecionar aleatoriamente 5 linhas de cada conjunto e removê-las
sample_cc6050 = df_cc6050.sample(n=5, random_state=42)
df_cc6050 = df_cc6050.drop(sample_cc6050.index)

sample_pcbn7025 = df_pcbn7025.sample(n=5, random_state=42)
df_pcbn7025 = df_pcbn7025.drop(sample_pcbn7025.index)

# Exibir os resultados
print("Amostra CC6050:")
print(sample_cc6050)

print("\nConjunto restante CC6050:")
print(df_cc6050)

print("\nAmostra PCBN7025:")
print(sample_pcbn7025)

print("\nConjunto restante PCBN7025:")
print(df_pcbn7025)

"""Análise de correlações"""

# Cálculo das correlações para CC6050
correlation_cc6050 = df_cc6050.corr()

# Exibir os resultados
print("Correlação - CC6050")
print(correlation_cc6050)

import matplotlib.pyplot as plt
import seaborn as sns

# Plot heatmap for CC6050
plt.figure(figsize=(6, 4))
sns.heatmap(correlation_cc6050, annot=True, cmap='coolwarm', cbar_kws={'label': 'Correlation Coefficient'})
plt.title('Correlation Heatmap - CC6050')
plt.xlabel('Variables')
plt.ylabel('Variables')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Ajuste da posição e escala da barra de cores com suporte para -1 a 1
g = sns.clustermap(
    correlation_cc6050,
    annot=True,
    cmap='viridis',
    figsize=(4, 4),  # Tamanho reduzido para (4, 4)
    dendrogram_ratio=(.15, .15),  # Ajuste dos dendrogramas
    cbar_pos=(1, 0.2, 0.03, 0.5),  # Posicionamento ajustado da barra de cor
    annot_kws={"size": 12},  # Tamanho das anotações
    vmin=-1,  # Valor mínimo definido para -1
    vmax=1,   # Valor máximo definido para 1
    cbar_kws={
        'ticks': np.arange(-1, 1.1, 0.5),  # Escala ajustada de -1 a 1 com intervalos de 0.5
        'label': 'Correlation (-1 to 1)'   # Legenda da barra de cores
    },
)
# Ajuste do título principal
plt.suptitle('Clustered Correlation Heatmap - CC6050', y=1.02, fontsize=14)

# Ajuste do tamanho da fonte nos rótulos dos eixos
plt.setp(g.ax_heatmap.xaxis.get_majorticklabels(), fontsize=12)  # Eixo X
plt.setp(g.ax_heatmap.yaxis.get_majorticklabels(), fontsize=12)  # Eixo Y

plt.show()

data_cc6050 = {
    "Vc": [100.00, 225.00, 100.00, 225.00, 100.00, 225.00, 100.00, 225.00, 57.39, 267.61,
           162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50],
    "f": [0.10, 0.10, 0.22, 0.22, 0.10, 0.10, 0.22, 0.22, 0.16, 0.16,
          0.05, 0.26, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16],
    "ap": [0.15, 0.15, 0.15, 0.15, 0.33, 0.33, 0.33, 0.33, 0.24, 0.24,
           0.24, 0.24, 0.09, 0.39, 0.24, 0.24, 0.24, 0.24, 0.24],
    "Ra": [0.62, 0.64, 0.98, 1.09, 0.65, 0.72, 1.33, 1.39, 1.12, 1.97,
           0.32, 1.35, 0.87, 0.95, 1.14, 1.13, 1.12, 1.14, 1.13]
}

df_cc6050 = pd.DataFrame(data_cc6050)

df_cc6050.info()

# Plotting 4 boxplots in 2 rows and 2 columns with adjusted outlier size and bar thickness
fig, axes = plt.subplots(2, 2, figsize=(3, 4))

# Customizations for all boxplots
boxplot_props = dict(boxprops=dict(linewidth=1), whiskerprops=dict(linewidth=1),
                     capprops=dict(linewidth=1), flierprops=dict(marker='o', markersize=4))

# Boxplots for each variable
axes[0, 0].boxplot(df_cc6050["Vc"], vert=True, patch_artist=True, **boxplot_props)
axes[0, 0].set_title("Vc (m/min)")
axes[0, 0].tick_params(axis='x', which='both', bottom=False, labelbottom=False)

axes[0, 1].boxplot(df_cc6050["f"], vert=True, patch_artist=True, **boxplot_props)
axes[0, 1].set_title("f (mm/rev)")
axes[0, 1].tick_params(axis='x', which='both', bottom=False, labelbottom=False)

axes[1, 0].boxplot(df_cc6050["ap"], vert=True, patch_artist=True, **boxplot_props)
axes[1, 0].set_title("ap (mm)")
axes[1, 0].tick_params(axis='x', which='both', bottom=False, labelbottom=False)

axes[1, 1].boxplot(df_cc6050["Ra"], vert=True, patch_artist=True, **boxplot_props)
axes[1, 1].set_title("Ra (µm)")
axes[1, 1].tick_params(axis='x', which='both', bottom=False, labelbottom=False)

# Adjust layout for better spacing
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, spearmanr, shapiro
from sklearn.metrics import mean_squared_error, r2_score
import statsmodels.api as sm

# Function to annotate correlation coefficients and p-values
def corrfunc(x, y, **kws):
    r, p = pearsonr(x, y)
    ax = plt.gca()
    ax.annotate(f'r = {r:.2f}\np = {p:.3f}', xy=(0.5, 0.5), xycoords=ax.transAxes,
                ha='center', va='center', fontsize=10, color='black')

g = sns.PairGrid(df_cc6050, vars=["Vc", "f", "ap", "Ra"], diag_sharey=False, height=1.7)

# Map the lower triangle with scatter plots
g.map_lower(sns.scatterplot, color='blue', alpha=0.6)

# Map the diagonal with univariate KDE plots
g.map_diag(sns.kdeplot, fill=True, color='green')

# Map the upper triangle with bivariate KDE plots
g.map_upper(sns.kdeplot, fill=True, cmap="Reds", alpha=0.5)

# Add main title
plt.suptitle("Pairplot of Vc, f, ap, and Ra with Density Curves", y=1.02, fontsize=18)

# Adjust font sizes for axis labels and ticks
for ax in g.axes.flatten():
    # Set the fontsize for x and y labels
    ax.set_xlabel(ax.get_xlabel(), fontsize=12)
    ax.set_ylabel(ax.get_ylabel(), fontsize=12)

    # Set the fontsize for tick labels
    ax.tick_params(axis='both', which='major', labelsize=12)

# Adjust layout and save the plot
plt.tight_layout()
plt.savefig("enhanced_pairplot_density_upper.png", dpi=300, bbox_inches='tight')
print("Pairplot with density curves saved as 'enhanced_pairplot_density_upper.png'.")
plt.show()

# Reimporting necessary libraries
import pandas as pd

# Recreating the dataset
data_cc6050_group = {
    "Vc": [100.00, 225.00, 100.00, 225.00, 100.00, 225.00, 100.00, 225.00, 57.39, 267.61,
           162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50, 162.50],
    "f": [0.10, 0.10, 0.22, 0.22, 0.10, 0.10, 0.22, 0.22, 0.16, 0.16,
          0.05, 0.26, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16],
    "ap": [0.15, 0.15, 0.15, 0.15, 0.33, 0.33, 0.33, 0.33, 0.24, 0.24,
           0.24, 0.24, 0.09, 0.39, 0.24, 0.24, 0.24, 0.24, 0.24],
    "Ra": [0.62, 0.64, 0.98, 1.09, 0.65, 0.72, 1.33, 1.39, 1.12, 1.97,
           0.32, 1.35, 0.87, 0.95, 1.14, 1.13, 1.12, 1.14, 1.13],
    "Kp": [2.46, 1.52, 1.92, 1.25, 3.01, 1.76, 2.33, 1.12, 3.18, 1.18,
           2.76, 1.43, 1.45, 1.87, 1.87, 1.85, 1.89, 1.85, 1.83]
}

# Creating the DataFrame
data_cc6050_group = pd.DataFrame(data_cc6050_group)

# Adding the "Tests" column as the index of experiments
data_cc6050_group["Tests"] = range(1, len(data_cc6050_group) + 1)

# Rearranging columns to place "Tests" as the first column
data_cc6050_group = data_cc6050_group[["Tests", "Vc", "f", "ap", "Ra", "Kp"]]

data_cc6050_group.describe()

data_cc6050_group.info()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage

# Supondo que 'data_cc6050_group' seja o dataset com a coluna 'Tests' e 'Ra'
# Se os dados já estão no formato correto, como mostrado acima, podemos prosseguir com a análise

# Extraímos as colunas relevantes para o clustering: 'Tests' e 'Ra'
data_cc6050_group = data_cc6050_group[['Tests', 'Ra']]  # Ajuste de acordo com o nome correto

# Realizando a análise de cluster (linkage de Ward)
Z = linkage(data_cc6050_group, method='ward', metric='euclidean')

# Criando o dendrograma
plt.figure(figsize=(4, 3))
dendrogram(Z, labels=data_cc6050_group['Tests'].values, leaf_rotation=90)
plt.title('Dendrogram of Tests and Surface Roughness (Ra)')
plt.xlabel('Tests')
plt.ylabel('Distance')
plt.show()

from scipy.spatial import ConvexHull
import matplotlib.pyplot as plt
import numpy as np

# Dados
X = data_cc6050_group[['Tests', 'Ra']]
kmeans = KMeans(n_clusters=3, random_state=42)
data_cc6050_group['Cluster_KMeans'] = kmeans.fit_predict(X)

# Criando a figura
plt.figure(figsize=(4, 3))
colors = ['blue', 'orange', 'green']

# Adicionando os pontos e envelopes convexos
for cluster_id in np.unique(data_cc6050_group['Cluster_KMeans']):
    cluster_data = X[data_cc6050_group['Cluster_KMeans'] == cluster_id].values
    hull = ConvexHull(cluster_data)

    # Desenhando o envelope convexo
    for simplex in hull.simplices:
        plt.plot(cluster_data[simplex, 0], cluster_data[simplex, 1], color=colors[cluster_id], lw=2)

    # Preenchendo o interior do polígono
    plt.fill(cluster_data[hull.vertices, 0], cluster_data[hull.vertices, 1], color=colors[cluster_id], alpha=0.2)

# Adicionando os pontos
plt.scatter(X['Tests'], X['Ra'], c=data_cc6050_group['Cluster_KMeans'], cmap='viridis', s=50)
plt.xlabel('Tests')
plt.ylabel('Ra (Roughness)')
plt.title('K-Means Clustering with Convex Hulls')
plt.show()

from matplotlib.patches import Ellipse

# Dados
X = data_cc6050_group[['Tests', 'Ra']]
kmeans = KMeans(n_clusters=3, random_state=42)
data_cc6050_group['Cluster_KMeans'] = kmeans.fit_predict(X)

# Criando a figura
plt.figure(figsize=(3, 3))
plt.scatter(X['Tests'], X['Ra'], c=data_cc6050_group['Cluster_KMeans'], cmap='viridis', s=100, label='Data Points')

# Calculando centróides e desenhando elipses ampliadas
for cluster_id in np.unique(data_cc6050_group['Cluster_KMeans']):
    cluster_data = X[data_cc6050_group['Cluster_KMeans'] == cluster_id]
    center = cluster_data.mean(axis=0)
    cov_matrix = cluster_data.cov()
    eig_vals, eig_vecs = np.linalg.eigh(cov_matrix)

    # Ampliando o tamanho da elipse
    scale_factor = 2  # Ajuste para garantir que todos os pontos estejam contidos
    width, height = scale_factor * 2 * np.sqrt(eig_vals)
    angle = np.degrees(np.arctan2(*eig_vecs[:, 0][::-1]))

    # Adicionando elipse ao gráfico
    ellipse = Ellipse(xy=center, width=width, height=height, angle=angle, edgecolor='black', facecolor='none', lw=2)
    plt.gca().add_patch(ellipse)

plt.xlabel('Tests')
plt.ylabel('Ra (Roughness)')
plt.title('K-Means Clustering with Scaled Ellipses')
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import pearsonr


# ==========================
# 2. Function to Add Correlation Coefficient and p-value
# ==========================
def add_stats_with_ci(ax, x, y, data):
    # Calculate Pearson correlation
    r, p = pearsonr(data[x], data[y])
    # Annotate the plot with r and p
    ax.annotate(f'r = {r:.2f}\np = {p:.3f}', xy=(0.05, 0.95), xycoords='axes fraction',
                ha='left', va='top', fontsize=12, backgroundcolor='white')

# ==========================
# 3. Create Subplots with Vertical Layout
# ==========================
fig, axes = plt.subplots(3, 1, figsize=(4, 8))  # 3 rows, 1 column

# ==========================
# 4. Plot Ra vs Vc with Enhanced Stats
# ==========================
sns.regplot(x='Vc', y='Ra', data=df_cc6050, ax=axes[0],
            scatter_kws={'s': 20, 'color': 'blue'}, line_kws={'color': 'red'},
            ci=95)  # 95% confidence interval
axes[0].set_title("Ra vs Vc", fontsize=14)
axes[0].set_xlabel("Vc (m/min)", fontsize=12)
axes[0].set_ylabel("Ra (Roughness)", fontsize=12)
add_stats_with_ci(axes[0], 'Vc', 'Ra', df_cc6050)

# ==========================
# 5. Plot Ra vs f with Enhanced Stats
# ==========================
sns.regplot(x='f', y='Ra', data=df_cc6050, ax=axes[1],
            scatter_kws={'s': 20, 'color': 'green'}, line_kws={'color': 'red'},
            ci=95)
axes[1].set_title("Ra vs f", fontsize=14)
axes[1].set_xlabel("f (mm/rev)", fontsize=12)
axes[1].set_ylabel("Ra (Roughness)", fontsize=12)
add_stats_with_ci(axes[1], 'f', 'Ra', df_cc6050)

# ==========================
# 6. Plot Ra vs ap with Enhanced Stats
# ==========================
sns.regplot(x='ap', y='Ra', data=df_cc6050, ax=axes[2],
            scatter_kws={'s': 20, 'color': 'orange'}, line_kws={'color': 'red'},
            ci=95)
axes[2].set_title("Ra vs ap", fontsize=14)
axes[2].set_xlabel("ap (mm)", fontsize=12)
axes[2].set_ylabel("Ra (Roughness)", fontsize=12)
add_stats_with_ci(axes[2], 'ap', 'Ra', df_cc6050)

# ==========================
# 7. Adjust Layout and Save the Plot
# ==========================
plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust to make space for the main title
#plt.suptitle("Enhanced Scatter Plots of Ra vs Vc, f, and ap with Correlation Coefficients", fontsize=20)
plt.savefig("vertical_enhanced_scatter_plots.png", dpi=300, bbox_inches='tight')
plt.show()

"""# **MACHINE LEARNING PARA CC6050**"""

!pip install scikeras

!pip install --upgrade scikit-learn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV, LeaveOneOut
from sklearn.metrics import mean_squared_error, r2_score, make_scorer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input, Dropout
from scikeras.wrappers import KerasRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeRegressor  # Importação da Árvore de Decisão
import tensorflow as tf
import random
from tensorflow.keras.callbacks import EarlyStopping

# ============================
# 1. Configurações Iniciais
# ============================

# Fixar sementes para reprodutibilidade
def set_seed(seed=42):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    random.seed(seed)

set_seed(42)

# ============================
# 2. Definição dos Dados
# ============================

# **Dados de Treinamento**
df_cc6050 = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39, 150.00, 200.00, 180.00, 210.00, 190.00],
    "f": [0.10, 0.10, 0.26, 0.10, 0.16, 0.20, 0.15, 0.25, 0.18, 0.22],
    "ap": [0.15, 0.33, 0.24, 0.15, 0.24, 0.20, 0.30, 0.22, 0.25, 0.28],
    "Ra": [0.62, 0.72, 1.35, 0.64, 1.12, 0.80, 0.90, 1.10, 0.75, 0.85]
})

# **Dados para Previsão (Novos Dados)**
amostra_cc6050 = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39],
    "f": [0.10, 0.10, 0.26, 0.10, 0.16],
    "ap": [0.15, 0.33, 0.24, 0.15, 0.24],
    "Ra": [0.62, 0.72, 1.35, 0.64, 1.12]  # Valores reais de Ra para comparação
})

# Separar entrada (X) e saídas reais (y) para treinamento
X_cc6050 = df_cc6050[["Vc", "f", "ap"]]
y_ra_cc6050 = df_cc6050["Ra"]

# Separar entrada (X_new) e saídas reais (y_new_true_ra) para previsão
X_new = amostra_cc6050[["Vc", "f", "ap"]]
y_new_true_ra = amostra_cc6050["Ra"]

# ============================
# 3. Função para Construir o Modelo DNN
# ============================

def build_dnn(optimizer='adam'):
    # Fixar a semente dentro da função de construção do modelo
    tf.random.set_seed(42)

    model = Sequential([
        Input(shape=(X_cc6050.shape[1],)),
        Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
        Dropout(0.2),
        Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
        Dropout(0.2),
        Dense(1)
    ])
    model.compile(optimizer=optimizer, loss='mse')
    return model

# ============================
# 4. Configuração e Treinamento do Modelo DNN com LOOCV
# ============================

# Configuração do pipeline DNN com scaler e EarlyStopping
early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)

pipeline_dnn_ra = Pipeline([
    ('scaler', StandardScaler()),
    ('dnn', KerasRegressor(model=build_dnn, verbose=0, callbacks=[early_stop]))
])

# Hiperparâmetros para GridSearch do DNN
dnn_params_ra = {
    'dnn__epochs': [100],
    'dnn__batch_size': [4, 8],
    'dnn__optimizer': ['adam', 'sgd']
}

# Definição do scorer para GridSearchCV
mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)

# Configuração do Leave-One-Out Cross-Validation
loo = LeaveOneOut()

# GridSearchCV para DNN com LOOCV
grid_dnn_ra = GridSearchCV(
    estimator=pipeline_dnn_ra,
    param_grid=dnn_params_ra,
    scoring=mse_scorer,
    cv=loo,
    n_jobs=-1,
    verbose=1,
    return_train_score=True
)

# Treinamento do GridSearch para DNN
print("Iniciando GridSearch para DNN com LOOCV...")
grid_dnn_ra.fit(X_cc6050, y_ra_cc6050)
print("GridSearch para DNN concluído.")

# Obter o melhor modelo DNN
best_model_dnn = grid_dnn_ra.best_estimator_

# ============================
# 5. Configuração e Treinamento do Modelo Árvore de Decisão com LOOCV
# ============================

# Hiperparâmetros para GridSearch da Árvore de Decisão
dt_params = {
    'max_depth': [3, 5, 7],          # Profundidade máxima da árvore
    'min_samples_split': [2, 4],     # Número mínimo de amostras para dividir um nó
    'min_samples_leaf': [1, 2],      # Número mínimo de amostras em uma folha
    'criterion': ['squared_error', 'friedman_mse']  # Atualizado
}

# Inicialização do modelo Árvore de Decisão
dt_model = DecisionTreeRegressor(random_state=42)

# GridSearchCV para Árvore de Decisão com LOOCV
grid_dt_ra = GridSearchCV(
    estimator=dt_model,
    param_grid=dt_params,
    scoring=mse_scorer,
    cv=loo,
    n_jobs=-1,
    verbose=1,
    return_train_score=True
)

# Treinamento do GridSearch para Árvore de Decisão
print("Iniciando GridSearch para Árvore de Decisão com LOOCV...")
grid_dt_ra.fit(X_cc6050, y_ra_cc6050)
print("GridSearch para Árvore de Decisão concluído.")

# Obter o melhor modelo Árvore de Decisão
best_model_dt = grid_dt_ra.best_estimator_

# ============================
# 6. Avaliação dos Modelos no Conjunto de Treinamento
# ============================

# **Avaliar o Modelo DNN**
y_pred_dnn = best_model_dnn.named_steps['dnn'].model_.predict(
    best_model_dnn.named_steps['scaler'].transform(X_cc6050)
)

mse_dnn = mean_squared_error(y_ra_cc6050, y_pred_dnn)
rmse_dnn = np.sqrt(mse_dnn)
r2_dnn = r2_score(y_ra_cc6050, y_pred_dnn)

# **Avaliar o Modelo Árvore de Decisão**
y_pred_dt = best_model_dt.predict(X_cc6050)

mse_dt = mean_squared_error(y_ra_cc6050, y_pred_dt)
rmse_dt = np.sqrt(mse_dt)
r2_dt = r2_score(y_ra_cc6050, y_pred_dt)

# ============================
# 7. Resultados da Validação Cruzada
# ============================

# Resultados da validação cruzada para DNN
cv_results_dnn = grid_dnn_ra.cv_results_
mse_scores_dnn = -cv_results_dnn['mean_test_score']
rmse_scores_dnn = np.sqrt(mse_scores_dnn)
print("\n=== Validação Cruzada - DNN ===")
for mean, std, params in zip(cv_results_dnn['mean_test_score'], cv_results_dnn['std_test_score'], cv_results_dnn['params']):
    print(f"MSE: {-mean:.4f} (+/- {std:.4f}) | Params: {params}")

# Resultados da validação cruzada para Árvore de Decisão
cv_results_dt = grid_dt_ra.cv_results_
mse_scores_dt = -cv_results_dt['mean_test_score']
rmse_scores_dt = np.sqrt(mse_scores_dt)
print("\n=== Validação Cruzada - Árvore de Decisão ===")
for mean, std, params in zip(cv_results_dt['mean_test_score'], cv_results_dt['std_test_score'], cv_results_dt['params']):
    print(f"MSE: {-mean:.4f} (+/- {std:.4f}) | Params: {params}")

# ============================
# 8. Resultados Finais
# ============================

print(f"\n=== Resultados no Conjunto de Treinamento ===")
print(f"DNN - MSE: {mse_dnn:.4f}, RMSE: {rmse_dnn:.4f}, R2: {r2_dnn:.4f}")
print(f"Decisão - MSE: {mse_dt:.4f}, RMSE: {rmse_dt:.4f}, R2: {r2_dt:.4f}")

print("\n=== Avaliação no Conjunto de Treinamento ===")
print("=== DNN Model ===")
print(f"Melhores Hiperparâmetros: {grid_dnn_ra.best_params_}")
print(f"MSE: {mse_dnn:.4f}")
print(f"RMSE: {rmse_dnn:.4f}")
print(f"R²: {r2_dnn:.4f}")

print("\n=== Árvore de Decisão Model ===")
print(f"Melhores Hiperparâmetros: {grid_dt_ra.best_params_}")
print(f"MSE: {mse_dt:.4f}")
print(f"RMSE: {rmse_dt:.4f}")
print(f"R²: {r2_dt:.4f}")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV, LeaveOneOut
from sklearn.metrics import mean_squared_error, r2_score, make_scorer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input, Dropout
from scikeras.wrappers import KerasRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeRegressor  # Importação da Árvore de Decisão
import tensorflow as tf
import random
from tensorflow.keras.callbacks import EarlyStopping

# ============================
# 1. Configurações Iniciais
# ============================

# Fixar sementes para reprodutibilidade
def set_seed(seed=42):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    random.seed(seed)

set_seed(42)

# ============================
# 2. Definição dos Dados
# ============================

# **Dados de Treinamento**
df_cc6050 = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39, 150.00, 200.00, 180.00, 210.00, 190.00],
    "f": [0.10, 0.10, 0.26, 0.10, 0.16, 0.20, 0.15, 0.25, 0.18, 0.22],
    "ap": [0.15, 0.33, 0.24, 0.15, 0.24, 0.20, 0.30, 0.22, 0.25, 0.28],
    "Ra": [0.62, 0.72, 1.35, 0.64, 1.12, 0.80, 0.90, 1.10, 0.75, 0.85]
})

# **Dados para Previsão (Novos Dados)**
amostra_cc6050 = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39],
    "f": [0.10, 0.10, 0.26, 0.10, 0.16],
    "ap": [0.15, 0.33, 0.24, 0.15, 0.24],
    "Ra": [0.62, 0.72, 1.35, 0.64, 1.12]  # Valores reais de Ra para comparação
})

# Separar entrada (X) e saídas reais (y) para treinamento
X_cc6050 = df_cc6050[["Vc", "f", "ap"]]
y_ra_cc6050 = df_cc6050["Ra"]

# Separar entrada (X_new) e saídas reais (y_new_true_ra) para previsão
X_new = amostra_cc6050[["Vc", "f", "ap"]]
y_new_true_ra = amostra_cc6050["Ra"]

# ============================
# 3. Função para Construir o Modelo DNN
# ============================

def build_dnn(optimizer='adam'):
    # Fixar a semente dentro da função de construção do modelo
    tf.random.set_seed(42)

    model = Sequential([
        Input(shape=(X_cc6050.shape[1],)),
        Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
        Dropout(0.2),
        Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
        Dropout(0.2),
        Dense(1)
    ])
    model.compile(optimizer=optimizer, loss='mse')
    return model

# ============================
# 4. Configuração e Treinamento do Modelo DNN com LOOCV
# ============================

# Configuração do pipeline DNN com scaler e EarlyStopping
early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)

pipeline_dnn_ra = Pipeline([
    ('scaler', StandardScaler()),
    ('dnn', KerasRegressor(model=build_dnn, verbose=0, callbacks=[early_stop]))
])

# Hiperparâmetros para GridSearch do DNN
dnn_params_ra = {
    'dnn__epochs': [100],
    'dnn__batch_size': [4, 8],
    'dnn__optimizer': ['adam', 'sgd']
}

# Definição do scorer para GridSearchCV
mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)

# Configuração do Leave-One-Out Cross-Validation
loo = LeaveOneOut()

# GridSearchCV para DNN com LOOCV
grid_dnn_ra = GridSearchCV(
    estimator=pipeline_dnn_ra,
    param_grid=dnn_params_ra,
    scoring=mse_scorer,
    cv=loo,
    n_jobs=-1,
    verbose=1,
    return_train_score=True
)

# Treinamento do GridSearch para DNN
print("Iniciando GridSearch para DNN com LOOCV...")
grid_dnn_ra.fit(X_cc6050, y_ra_cc6050)
print("GridSearch para DNN concluído.")

# Obter o melhor modelo DNN
best_model_dnn = grid_dnn_ra.best_estimator_

# ============================
# 5. Configuração e Treinamento do Modelo Árvore de Decisão com LOOCV
# ============================

# Hiperparâmetros para GridSearch da Árvore de Decisão
dt_params = {
    'max_depth': [3, 5, 7],          # Profundidade máxima da árvore
    'min_samples_split': [2, 4],     # Número mínimo de amostras para dividir um nó
    'min_samples_leaf': [1, 2],      # Número mínimo de amostras em uma folha
    'criterion': ['squared_error', 'friedman_mse']  # Atualizado
}

# Inicialização do modelo Árvore de Decisão
dt_model = DecisionTreeRegressor(random_state=42)

# GridSearchCV para Árvore de Decisão com LOOCV
grid_dt_ra = GridSearchCV(
    estimator=dt_model,
    param_grid=dt_params,
    scoring=mse_scorer,
    cv=loo,
    n_jobs=-1,
    verbose=1,
    return_train_score=True
)

# Treinamento do GridSearch para Árvore de Decisão
print("Iniciando GridSearch para Árvore de Decisão com LOOCV...")
grid_dt_ra.fit(X_cc6050, y_ra_cc6050)
print("GridSearch para Árvore de Decisão concluído.")

# Obter o melhor modelo Árvore de Decisão
best_model_dt = grid_dt_ra.best_estimator_

# ============================
# 6. Avaliação dos Modelos no Conjunto de Treinamento
# ============================

# **Avaliar o Modelo DNN**
y_pred_dnn = best_model_dnn.named_steps['dnn'].model_.predict(
    best_model_dnn.named_steps['scaler'].transform(X_cc6050)
)

mse_dnn = mean_squared_error(y_ra_cc6050, y_pred_dnn)
rmse_dnn = np.sqrt(mse_dnn)
r2_dnn = r2_score(y_ra_cc6050, y_pred_dnn)

# **Avaliar o Modelo Árvore de Decisão**
y_pred_dt = best_model_dt.predict(X_cc6050)

mse_dt = mean_squared_error(y_ra_cc6050, y_pred_dt)
rmse_dt = np.sqrt(mse_dt)
r2_dt = r2_score(y_ra_cc6050, y_pred_dt)

# ============================
# 7. Resultados da Validação Cruzada
# ============================

# Resultados da validação cruzada para DNN
cv_results_dnn = grid_dnn_ra.cv_results_
mse_scores_dnn = -cv_results_dnn['mean_test_score']
rmse_scores_dnn = np.sqrt(mse_scores_dnn)
print("\n=== Validação Cruzada - DNN ===")
for mean, std, params in zip(cv_results_dnn['mean_test_score'], cv_results_dnn['std_test_score'], cv_results_dnn['params']):
    print(f"MSE: {-mean:.4f} (+/- {std:.4f}) | Params: {params}")

# Resultados da validação cruzada para Árvore de Decisão
cv_results_dt = grid_dt_ra.cv_results_
mse_scores_dt = -cv_results_dt['mean_test_score']
rmse_scores_dt = np.sqrt(mse_scores_dt)
print("\n=== Validação Cruzada - Árvore de Decisão ===")
for mean, std, params in zip(cv_results_dt['mean_test_score'], cv_results_dt['std_test_score'], cv_results_dt['params']):
    print(f"MSE: {-mean:.4f} (+/- {std:.4f}) | Params: {params}")

# ============================
# 8. Resultados Finais
# ============================

print(f"\n=== Resultados no Conjunto de Treinamento ===")
print(f"DNN - MSE: {mse_dnn:.4f}, RMSE: {rmse_dnn:.4f}, R2: {r2_dnn:.4f}")
print(f"Decisão - MSE: {mse_dt:.4f}, RMSE: {rmse_dt:.4f}, R2: {r2_dt:.4f}")

# ============================
# 9. Bloco Adicional: Previsões com Novos Dados
# ============================

# **Previsões com Novos Dados usando DNN e Árvore de Decisão**

# Fazer previsões com o modelo DNN (o pipeline inclui o scaler)
y_pred_dnn_new = best_model_dnn.named_steps['dnn'].model_.predict(
    best_model_dnn.named_steps['scaler'].transform(X_new)
)

# Fazer previsões com o modelo Árvore de Decisão
y_pred_dt_new = best_model_dt.predict(X_new)

# **Cálculo das Métricas para Novas Previsões**

# Métricas para DNN
mse_dnn_new = mean_squared_error(y_new_true_ra, y_pred_dnn_new)
rmse_dnn_new = np.sqrt(mse_dnn_new)
r2_dnn_new = r2_score(y_new_true_ra, y_pred_dnn_new)

# Métricas para Árvore de Decisão
mse_dt_new = mean_squared_error(y_new_true_ra, y_pred_dt_new)
rmse_dt_new = np.sqrt(mse_dt_new)
r2_dt_new = r2_score(y_new_true_ra, y_pred_dt_new)

# **Comparação das Métricas nos Novos Dados**
metrics_comparison_new = pd.DataFrame({
    "Model": ["DNN", "Árvore de Decisão"],
    "MSE": [mse_dnn_new, mse_dt_new],
    "RMSE": [rmse_dnn_new, rmse_dt_new],
    "R²": [r2_dnn_new, r2_dt_new]
})

print("\n=== Comparação das Métricas nos Novos Dados ===")
print(metrics_comparison_new)

from sklearn.model_selection import learning_curve

# Curvas de Aprendizagem para Árvore de Decisão
train_sizes_dt, train_scores_dt, test_scores_dt = learning_curve(
    estimator=best_model_dt,
    X=X_cc6050,
    y=y_ra_cc6050,
    train_sizes=np.linspace(0.1, 1.0, 10),
    cv=loo,
    scoring='neg_mean_squared_error',
    n_jobs=-1
)

# Calcular RMSE para Treinamento e Validação
train_rmse_dt = np.sqrt(-train_scores_dt.mean(axis=1))
test_rmse_dt = np.sqrt(-test_scores_dt.mean(axis=1))

# Plotar Curvas de Aprendizagem para Árvore de Decisão
plt.figure(figsize=(5, 3))
plt.plot(train_sizes_dt, train_rmse_dt, label='Training RMSE', color='blue', marker='o')
plt.plot(train_sizes_dt, test_rmse_dt, label='Validation RMSE', color='red', marker='x')
plt.title('Learning Curve - Decision Tree', fontsize=16)
plt.xlabel('Training Set Size', fontsize=14)
plt.ylabel('RMSE', fontsize=14)
plt.legend(fontsize=12)
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV, LeaveOneOut, train_test_split
from sklearn.metrics import mean_squared_error, r2_score, make_scorer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input, Dropout
from scikeras.wrappers import KerasRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeRegressor  # Importação da Árvore de Decisão
import tensorflow as tf
import random
from tensorflow.keras.callbacks import EarlyStopping

# ============================
# 1. Configurações Iniciais
# ============================

# Fixar sementes para reprodutibilidade
def set_seed(seed=42):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    random.seed(seed)

set_seed(42)

# ============================
# 2. Definição dos Dados
# ============================

# **Dados de Treinamento**
df_cc6050 = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39, 150.00, 200.00, 180.00, 210.00, 190.00],
    "f": [0.10, 0.10, 0.26, 0.10, 0.16, 0.20, 0.15, 0.25, 0.18, 0.22],
    "ap": [0.15, 0.33, 0.24, 0.15, 0.24, 0.20, 0.30, 0.22, 0.25, 0.28],
    "Ra": [0.62, 0.72, 1.35, 0.64, 1.12, 0.80, 0.90, 1.10, 0.75, 0.85]
})

# **Dados para Previsão (Novos Dados)**
amostra_cc6050 = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39],
    "f": [0.10, 0.10, 0.26, 0.10, 0.16],
    "ap": [0.15, 0.33, 0.24, 0.15, 0.24],
    "Ra": [0.62, 0.72, 1.35, 0.64, 1.12]  # Valores reais de Ra para comparação
})

# Separar entrada (X) e saídas reais (y) para treinamento
X_cc6050 = df_cc6050[["Vc", "f", "ap"]]
y_ra_cc6050 = df_cc6050["Ra"]

# Separar entrada (X_new) e saídas reais (y_new_true_ra) para previsão
X_new = amostra_cc6050[["Vc", "f", "ap"]]
y_new_true_ra = amostra_cc6050["Ra"]

# ============================
# 3. Função para Construir o Modelo DNN
# ============================

def build_dnn(optimizer='adam'):
    # Fixar a semente dentro da função de construção do modelo
    tf.random.set_seed(42)

    model = Sequential([
        Input(shape=(X_cc6050.shape[1],)),
        Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
        Dropout(0.2),
        Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
        Dropout(0.2),
        Dense(1)
    ])
    model.compile(optimizer=optimizer, loss='mse')
    return model

# ============================
# 4. Treinamento do Modelo DNN e Captura do Histórico
# ============================

# Dividir os dados em conjuntos de treino e validação para capturar o histórico
X_train_dnn, X_val_dnn, y_train_dnn, y_val_dnn = train_test_split(
    X_cc6050, y_ra_cc6050, test_size=0.2, random_state=42
)

# Escalar os dados
scaler_dnn = StandardScaler()
X_train_scaled_dnn = scaler_dnn.fit_transform(X_train_dnn)
X_val_scaled_dnn = scaler_dnn.transform(X_val_dnn)

# Construir o modelo
model_dnn = build_dnn(optimizer='adam')

# Definir Early Stopping
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Treinar o modelo e capturar o histórico
history_dnn = model_dnn.fit(
    X_train_scaled_dnn,
    y_train_dnn,
    epochs=100,
    batch_size=4,
    validation_data=(X_val_scaled_dnn, y_val_dnn),
    callbacks=[early_stop],
    verbose=0  # Defina como 1 para ver o progresso
)

# ============================
# 5. Treinamento do Modelo Árvore de Decisão com LOOCV
# ============================

# Configuração do Leave-One-Out Cross-Validation
loo = LeaveOneOut()

# Hiperparâmetros para GridSearch da Árvore de Decisão
dt_params = {
    'max_depth': [3, 5, 7],          # Profundidade máxima da árvore
    'min_samples_split': [2, 4],     # Número mínimo de amostras para dividir um nó
    'min_samples_leaf': [1, 2],      # Número mínimo de amostras em uma folha
    'criterion': ['squared_error', 'friedman_mse']  # Critério de divisão
}

# Inicialização do modelo Árvore de Decisão
dt_model = DecisionTreeRegressor(random_state=42)

# Definição do scorer para GridSearchCV
mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)

# GridSearchCV para Árvore de Decisão com LOOCV
grid_dt_ra = GridSearchCV(
    estimator=dt_model,
    param_grid=dt_params,
    scoring=mse_scorer,
    cv=loo,
    n_jobs=-1,
    verbose=1,
    return_train_score=True
)

# Treinamento do GridSearch para Árvore de Decisão
print("Iniciando GridSearch para Árvore de Decisão com LOOCV...")
grid_dt_ra.fit(X_cc6050, y_ra_cc6050)
print("GridSearch para Árvore de Decisão concluído.")

# Obter o melhor modelo Árvore de Decisão
best_model_dt = grid_dt_ra.best_estimator_

# ============================
# 6. Avaliação dos Modelos no Conjunto de Treinamento
# ============================

# **Avaliar o Modelo DNN no Conjunto de Validação**
y_pred_dnn_val = model_dnn.predict(X_val_scaled_dnn)
mse_dnn_val = mean_squared_error(y_val_dnn, y_pred_dnn_val)
rmse_dnn_val = np.sqrt(mse_dnn_val)
r2_dnn_val = r2_score(y_val_dnn, y_pred_dnn_val)

# **Avaliar o Modelo Árvore de Decisão no Conjunto de Treinamento Completo**
y_pred_dt = best_model_dt.predict(X_cc6050)
mse_dt = mean_squared_error(y_ra_cc6050, y_pred_dt)
rmse_dt = np.sqrt(mse_dt)
r2_dt = r2_score(y_ra_cc6050, y_pred_dt)

# ============================
# 7. Resultados da Validação Cruzada para Árvore de Decisão
# ============================

# Resultados da validação cruzada para Árvore de Decisão
cv_results_dt = grid_dt_ra.cv_results_
mse_scores_dt = -cv_results_dt['mean_test_score']
rmse_scores_dt = np.sqrt(mse_scores_dt)
print("\n=== Validação Cruzada - Árvore de Decisão ===")
for mean, std, params in zip(cv_results_dt['mean_test_score'], cv_results_dt['std_test_score'], cv_results_dt['params']):
    print(f"MSE: {-mean:.4f} (+/- {std:.4f}) | Params: {params}")

# ============================
# 8. Resultados Finais
# ============================

print(f"\n=== Resultados no Conjunto de Validação (DNN) ===")
print(f"DNN - MSE: {mse_dnn_val:.4f}, RMSE: {rmse_dnn_val:.4f}, R2: {r2_dnn_val:.4f}")
print(f"Árvore de Decisão - MSE: {mse_dt:.4f}, RMSE: {rmse_dt:.4f}, R2: {r2_dt:.4f}")

# ============================
# 9. Bloco Adicional: Previsões com Novos Dados
# ============================

# **Previsões com Novos Dados usando DNN e Árvore de Decisão**

# Escalar os novos dados para o DNN
X_new_scaled = scaler_dnn.transform(X_new)

# Fazer previsões com o modelo DNN
y_pred_dnn_new = model_dnn.predict(X_new_scaled)

# Fazer previsões com o modelo Árvore de Decisão
y_pred_dt_new = best_model_dt.predict(X_new)

# **Cálculo das Métricas para Novas Previsões**

# Métricas para DNN
mse_dnn_new = mean_squared_error(y_new_true_ra, y_pred_dnn_new)
rmse_dnn_new = np.sqrt(mse_dnn_new)
r2_dnn_new = r2_score(y_new_true_ra, y_pred_dnn_new)

# Métricas para Árvore de Decisão
mse_dt_new = mean_squared_error(y_new_true_ra, y_pred_dt_new)
rmse_dt_new = np.sqrt(mse_dt_new)
r2_dt_new = r2_score(y_new_true_ra, y_pred_dt_new)

# **Comparação das Métricas nos Novos Dados**
metrics_comparison_new = pd.DataFrame({
    "Model": ["DNN", "Árvore de Decisão"],
    "MSE": [mse_dnn_new, mse_dt_new],
    "RMSE": [rmse_dnn_new, rmse_dt_new],
    "R²": [r2_dnn_new, r2_dt_new]
})

print("\n=== Comparação das Métricas nos Novos Dados ===")
print(metrics_comparison_new)

# ============================
# 10. Plotando as Curvas de Aprendizado
# ============================

def plot_learning_curve_dnn(history, title):
    """
    Plota as curvas de perda de treinamento e validação para o modelo DNN.

    Parameters:
    - history: Objeto History retornado pelo método fit do Keras.
    - title: Título do gráfico.
    """
    plt.figure(figsize=(4, 3))
    plt.plot(history.history['loss'], label='Perda de Treinamento')
    plt.plot(history.history['val_loss'], label='Perda de Validação')
    plt.title(title)
    plt.xlabel('Épocas')
    plt.ylabel('MSE (Mean Squared Error)')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

def plot_learning_curve_sklearn(estimator, X, y, title, cv, train_sizes, scoring):
    """
    Plota a curva de aprendizado para um estimador do scikit-learn.

    Parameters:
    - estimator: O modelo a ser treinado.
    - X: Dados de entrada.
    - y: Dados de saída.
    - title: Título do gráfico.
    - cv: Estratégia de cross-validation.
    - train_sizes: Tamanhos dos conjuntos de treinamento.
    - scoring: Métrica de avaliação.
    """
    plt.figure(figsize=(4, 3))
    plt.title(title)
    plt.xlabel("Tamanho do Conjunto de Treinamento")
    plt.ylabel("Média da Métrica de Avaliação (MSE)")

    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, train_sizes=train_sizes,
        scoring=scoring, n_jobs=-1, shuffle=True, random_state=42
    )

    train_scores_mean = -np.mean(train_scores, axis=1)  # Negativo porque 'neg_mean_squared_error'
    train_scores_std = np.std(-train_scores, axis=1)
    test_scores_mean = -np.mean(test_scores, axis=1)
    test_scores_std = np.std(-test_scores, axis=1)

    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1,
                     color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Pontuação de Treinamento")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Pontuação de Validação Cruzada")

    plt.legend(loc="best")
    plt.tight_layout()
    plt.show()

# Definir os tamanhos dos conjuntos de treinamento para a Árvore de Decisão
train_sizes_dt = np.linspace(0.2, 1.0, 5)

# Plot para o Modelo DNN
print("\nPlotando Curva de Perda para o Modelo DNN...")
plot_learning_curve_dnn(
    history=history_dnn,
    title="Curva de Perda - DNN"
)

# Plot para o Modelo Árvore de Decisão
print("Plotando Curva de Aprendizado para o Modelo Árvore de Decisão...")
plot_learning_curve_sklearn(
    estimator=best_model_dt,
    X=X_cc6050,
    y=y_ra_cc6050,
    title="Curva de Aprendizado - Árvore de Decisão",
    cv=loo,
    train_sizes=train_sizes_dt,
    scoring='neg_mean_squared_error'
)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve

# Plotting Functions
def plot_learning_curve_dnn(history, title="Learning Curve - DNN"):
    """
    Plots the training and validation loss curves for the DNN model.

    Parameters:
    - history: History object returned by the Keras fit method.
    - title: Title of the plot (string).
    """
    plt.figure(figsize=(4, 3))
    plt.plot(history.history['loss'], label='Training Loss', color='blue', linewidth=2)
    plt.plot(history.history['val_loss'], label='Validation Loss', color='orange', linewidth=2)
    plt.title(title, fontsize=12)
    plt.xlabel('Epochs', fontsize=11)
    plt.ylabel('Mean Squared Error (MSE)', fontsize=11)
    plt.legend(fontsize=10)
    plt.grid(True)
    plt.tight_layout()
    plt.show()

def plot_learning_curve_dt(estimator, X, y, cv, train_sizes=np.linspace(0.2, 1.0, 5), scoring='neg_mean_squared_error', title="Learning Curve - Decision Tree"):
    """
    Plots the learning curve for a scikit-learn estimator (Decision Tree).

    Parameters:
    - estimator: The trained model (e.g., best_model_dt).
    - X: Input features.
    - y: Target variable.
    - cv: Cross-validation strategy (e.g., LeaveOneOut()).
    - train_sizes: Array of training set sizes.
    - scoring: Evaluation metric.
    - title: Title of the plot (string).
    """
    plt.figure(figsize=(4, 3))
    plt.title(title, fontsize=12)
    plt.xlabel("Training Set Size (%)", fontsize=11)
    plt.ylabel("Mean Evaluation Metric (MSE)", fontsize=11)

    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, train_sizes=train_sizes,
        scoring=scoring, n_jobs=-1, shuffle=True, random_state=42
    )

    # Convert negative scores to positive if necessary
    if scoring.startswith('neg_'):
        train_scores = -train_scores
        test_scores = -test_scores

    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std  = np.std(train_scores, axis=1)
    test_scores_mean  = np.mean(test_scores, axis=1)
    test_scores_std   = np.std(test_scores, axis=1)

    plt.grid(True)

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1,
                     color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Training Score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Cross-Validation Score")

    plt.legend(loc="best", fontsize=10)
    plt.tight_layout()
    plt.show()

# Example Usage
# Assuming you have already trained your models and have the following objects:
# - history_dnn: History object from training the DNN model
# - best_model_dt: Trained Decision Tree model
# - X_cc6050, y_ra_cc6050: Your dataset features and target
# - loo: LeaveOneOut cross-validator

# Plotting the Learning Curve for the DNN Model
plot_learning_curve_dnn(history=history_dnn, title="Learning Curve - DNN")

# Plotting the Learning Curve for the Decision Tree Model
plot_learning_curve_dt(
    estimator=best_model_dt,
    X=X_cc6050,
    y=y_ra_cc6050,
    cv=loo,
    train_sizes=np.linspace(0.2, 1.0, 5),
    scoring='neg_mean_squared_error',
    title="Learning Curve - Decision Tree"
)

!pip install --upgrade scikit-learn
!pip install --upgrade scikeras

# **Plotagem dos Resultados das Previsões**
plt.figure(figsize=(5, 3))
plt.plot(range(1, len(y_new_true_ra) + 1), y_new_true_ra, marker='o', label='True Ra')
plt.plot(range(1, len(y_pred_dnn_new) + 1), y_pred_dnn_new, marker='x', label='Predicted Ra (DNN)')
plt.plot(range(1, len(y_pred_dt_new) + 1), y_pred_dt_new, marker='s', label='Predicted Ra (Árvore de Decisão)')
plt.title('Predicted vs True Ra - Novos Dados (DNN e Árvore de Decisão)')
plt.xlabel('Caso de Teste')
plt.ylabel('Ra')
plt.xticks(range(1, len(y_new_true_ra) + 1))  # Números dos testes
plt.legend(fontsize=8)
plt.grid()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score

# **Ensure the arrays are 1D**
y_new_true_ra = np.array(y_new_true_ra).flatten()  # Flattening if it's not 1D
y_pred_dnn_new = np.array(y_pred_dnn_new).flatten()
y_pred_dt_new = np.array(y_pred_dt_new).flatten()

# **Calculate Metrics**
mse_dnn = mean_squared_error(y_new_true_ra, y_pred_dnn_new)
rmse_dnn = np.sqrt(mse_dnn)
r2_dnn = r2_score(y_new_true_ra, y_pred_dnn_new)

mse_dt = mean_squared_error(y_new_true_ra, y_pred_dt_new)
rmse_dt = np.sqrt(mse_dt)
r2_dt = r2_score(y_new_true_ra, y_pred_dt_new)

# **Metrics Summary**
metrics_summary = pd.DataFrame({
    'Model': ['DNN', 'Decision Tree'],
    'MSE': [mse_dnn, mse_dt],
    'RMSE': [rmse_dnn, rmse_dt],
    'R²': [r2_dnn, r2_dt]
})
print(metrics_summary)

# **Create the Comparison Table**
data_comparison = pd.DataFrame({
    'Test Case': range(1, len(y_new_true_ra) + 1),
    'Actual Ra': y_new_true_ra,
    'Predicted Ra (DNN)': y_pred_dnn_new,
    'Predicted Ra (Decision Tree)': y_pred_dt_new
})
print(data_comparison)

# **Plot Predicted vs True Values**
plt.figure(figsize=(4, 2.8))
plt.plot(data_comparison['Test Case'], data_comparison['Actual Ra'], marker='o', label='Actual Ra')
plt.plot(data_comparison['Test Case'], data_comparison['Predicted Ra (DNN)'], marker='x', label='Predicted Ra (DNN)')
plt.plot(data_comparison['Test Case'], data_comparison['Predicted Ra (Decision Tree)'], marker='s', label='Predicted Ra (Decision Tree)')

# Ajustar título e rótulos com tamanhos de fonte personalizados
plt.title('Actual vs Predicted Ra Values (ML Models)', fontsize=12)  # Título
plt.xlabel('Test Case', fontsize=10)  # Rótulo do eixo x
plt.ylabel('Ra (Roughness)', fontsize=10)  # Rótulo do eixo y

# Ajustar os ticks do eixo x e y
plt.xticks(data_comparison['Test Case'], fontsize=10)  # Rótulos dos ticks do eixo x
plt.yticks(fontsize=9)  # Rótulos dos ticks do eixo y

# Ajustar a legenda
plt.legend(fontsize=8)

# Adicionar grade
plt.grid()

# Mostrar o gráfico
plt.show()

"""# **PREVISÃO USANDO CHAT GPT-o1**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, r2_score
from scipy.stats import pearsonr
import statsmodels.api as sm

# ==========================
# 1. Define the Data
# ==========================
# Real values
df_cc6050 = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39],
    "f": [0.10, 0.10, 0.26, 0.10, 0.16],
    "ap": [0.15, 0.15, 0.15, 0.16, 0.24],
    "Ra": [0.62, 0.72, 1.35, 0.64, 1.12]  # Real Ra values
})

# Predicted Ra values from three tests (GPT-4o Mini)
predictions_test1 = [0.59, 0.71, 1.19, 0.63, 0.82]  # Test 1
predictions_test2 = [0.62, 0.72, 0.98, 0.64, 1.12]  # Test 2
predictions_test3 = [0.62, 0.72, 1.21, 0.64, 0.90]  # Test 3

# Add predictions to the DataFrame
df_cc6050["Ra_Predicted_Test1"] = predictions_test1
df_cc6050["Ra_Predicted_Test2"] = predictions_test2
df_cc6050["Ra_Predicted_Test3"] = predictions_test3

print("\n=== Dataset Overview ===")
print(df_cc6050.info())
print("\nFirst 5 Rows:")
print(df_cc6050.head())

# ==========================
# 2. Calculate Metrics
# ==========================
def calculate_metrics(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    return mse, rmse, r2

# Calculate metrics for each test
mse1, rmse1, r2_1 = calculate_metrics(df_cc6050["Ra"], df_cc6050["Ra_Predicted_Test1"])
mse2, rmse2, r2_2 = calculate_metrics(df_cc6050["Ra"], df_cc6050["Ra_Predicted_Test2"])
mse3, rmse3, r2_3 = calculate_metrics(df_cc6050["Ra"], df_cc6050["Ra_Predicted_Test3"])

# Organize metrics into a DataFrame
metrics_df = pd.DataFrame({
    "Test": ["Test 1", "Test 2", "Test 3"],
    "MSE": [mse1, mse2, mse3],
    "RMSE": [rmse1, rmse2, rmse3],
    "R²": [r2_1, r2_2, r2_3]
})

# Display metrics
print("\n=== Metrics for Each Test ===")
print(metrics_df)

# ==========================
# 3. Create Comparative Table
# ==========================
# Select relevant columns
comparison_df = df_cc6050[["Vc", "f", "ap", "Ra", "Ra_Predicted_Test1", "Ra_Predicted_Test2", "Ra_Predicted_Test3"]]

# Rename columns for clarity
comparison_df.columns = [
    "Vc (m/min)",
    "f (mm/rev)",
    "ap (mm)",
    "Ra (Real)",
    "Ra_Predicted_Test1",
    "Ra_Predicted_Test2",
    "Ra_Predicted_Test3"
]

# Display comparative table
print("\n=== Comparative Table: Actual vs. Predicted Ra ===")
print(comparison_df)

# Optional: Save the comparative table as Excel
comparison_df.to_excel("comparative_ra_predictions.xlsx", index=False)
print("\nComparative table saved as 'comparative_ra_predictions.xlsx'.")

# ==========================
# 4. Plot Enhanced Scatter Plots
# ==========================
def add_stats(ax, x, y, data):
    r, p = pearsonr(data[x], data[y])
    ax.annotate(f'r = {r:.2f}\np = {p:.3f}', xy=(0.05, 0.95), xycoords='axes fraction',
                ha='left', va='top', fontsize=12, backgroundcolor='white')

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Ra vs Vc
sns.regplot(x='Vc', y='Ra', data=df_cc6050, ax=axes[0],
            scatter_kws={'s': 100, 'color': 'blue'}, line_kws={'color': 'red'}, ci=95)
axes[0].set_title("Ra vs Vc")
axes[0].set_xlabel("Vc (m/min)")
axes[0].set_ylabel("Ra (Roughness)")
add_stats(axes[0], 'Vc', 'Ra', df_cc6050)

# Ra vs f
sns.regplot(x='f', y='Ra', data=df_cc6050, ax=axes[1],
            scatter_kws={'s': 100, 'color': 'green'}, line_kws={'color': 'red'}, ci=95)
axes[1].set_title("Ra vs f")
axes[1].set_xlabel("f (mm/rev)")
axes[1].set_ylabel("Ra (Roughness)")
add_stats(axes[1], 'f', 'Ra', df_cc6050)

# Ra vs ap
sns.regplot(x='ap', y='Ra', data=df_cc6050, ax=axes[2],
            scatter_kws={'s': 100, 'color': 'orange'}, line_kws={'color': 'red'}, ci=95)
axes[2].set_title("Ra vs ap")
axes[2].set_xlabel("ap (mm)")
axes[2].set_ylabel("Ra (Roughness)")
add_stats(axes[2], 'ap', 'Ra', df_cc6050)

plt.tight_layout()
plt.savefig("enhanced_scatter_plots.png")
print("Enhanced scatter plots saved as 'enhanced_scatter_plots.png'.")
plt.show()

# ==========================
# 5. Plot Line Graph Comparing Actual and Predicted Values
# ==========================
plt.figure(figsize=(5, 3))

# Plot actual Ra values
plt.plot(range(1, len(df_cc6050["Ra"]) + 1), df_cc6050["Ra"], marker='o', label='Actual Ra', linewidth=2)

# Plot predicted Ra values for each test
plt.plot(range(1, len(predictions_test1) + 1), predictions_test1, marker='x', linestyle='--', label='Predicted Ra (Test 1)', linewidth=1.5)
plt.plot(range(1, len(predictions_test2) + 1), predictions_test2, marker='s', linestyle='--', label='Predicted Ra (Test 2)', linewidth=1.5)
plt.plot(range(1, len(predictions_test3) + 1), predictions_test3, marker='d', linestyle='--', label='Predicted Ra (Test 3)', linewidth=1.5)

# Add title and labels
plt.title('Actual vs. Predicted Ra Values (GPT-4o Mini Tests)', fontsize=16)
plt.xlabel('Test Case', fontsize=14)
plt.ylabel('Ra (Roughness)', fontsize=14)
plt.xticks(range(1, len(df_cc6050["Ra"]) + 1))
plt.legend(fontsize=8)
plt.grid(True)
plt.tight_layout()
plt.savefig("actual_vs_predicted_ra_tests.png")
print("Line plot saved as 'actual_vs_predicted_ra_tests.png'.")
plt.show()

# ==========================
# 5. Plot Line Graph Comparing Actual and Predicted Values
# ==========================
plt.figure(figsize=(4, 3))

# Plot actual Ra values
plt.plot(range(1, len(df_cc6050["Ra"]) + 1), df_cc6050["Ra"], marker='o', label='Actual Ra', linewidth=2)

# Plot predicted Ra values for each test
plt.plot(range(1, len(predictions_test1) + 1), predictions_test1, marker='x', linestyle='--', label='Predicted Ra (Test 1)', linewidth=1.5)
plt.plot(range(1, len(predictions_test2) + 1), predictions_test2, marker='s', linestyle='--', label='Predicted Ra (Test 2)', linewidth=1.5)
plt.plot(range(1, len(predictions_test3) + 1), predictions_test3, marker='d', linestyle='--', label='Predicted Ra (Test 3)', linewidth=1.5)

# Add title and labels
plt.title('Actual vs. Predicted Ra Values (GPT-4o1)', fontsize=12)
plt.xlabel('Test Case', fontsize=10)
plt.ylabel('Ra (Roughness)', fontsize=10)
plt.xticks(range(1, len(df_cc6050["Ra"]) + 1))
plt.legend(fontsize=8)
plt.grid(True)
plt.tight_layout()
#plt.savefig("actual_vs_predicted_ra_tests.png")
print("Line plot saved as 'actual_vs_predicted_ra_tests.png'.")
plt.show()

"""# **PREVISÕES COM GPT - o1-mini**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score

# ==========================
# 1. Definir os Dados
# ==========================
# Valores reais
real_values = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39],
    "f": [0.10, 0.10, 0.26, 0.10, 0.16],
    "ap": [0.15, 0.33, 0.24, 0.15, 0.24],
    "Ra": [0.62, 0.72, 1.35, 0.64, 1.12]  # Valores reais de Ra
})

# Previsões dos três testes (GPT-4o Mini)
predictions_4o_mini_test1 = [0.868, 1.311, 0.759, 0.868, 0.965]
predictions_4o_mini_test2 = [0.818, 0.979, 0.876, 0.818, 0.889]
predictions_4o_mini_test3 = [0.23, 0.75, 0.97, 0.48, 0.45]

# ==========================
# 2. Cálculo das Métricas
# ==========================
def calculate_metrics(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    return mse, rmse, r2

# Calcular métricas para os testes
mse1, rmse1, r2_1 = calculate_metrics(real_values["Ra"], predictions_4o_mini_test1)
mse2, rmse2, r2_2 = calculate_metrics(real_values["Ra"], predictions_4o_mini_test2)
mse3, rmse3, r2_3 = calculate_metrics(real_values["Ra"], predictions_4o_mini_test3)

# Organizar métricas em um DataFrame
metrics_df = pd.DataFrame({
    "Test": ["Test 1", "Test 2", "Test 3"],
    "MSE": [mse1, mse2, mse3],
    "RMSE": [rmse1, rmse2, rmse3],
    "R²": [r2_1, r2_2, r2_3]
})

# Exibir as métricas
print("\nMetrics for GPT-4o Mini Tests:")
print(metrics_df)

# ==========================
# 3. Plotar Gráfico
# ==========================
plt.figure(figsize=(4, 3))

# Plotar valores reais
plt.plot(range(1, len(real_values["Ra"]) + 1), real_values["Ra"], marker='o', label='Actual Values')

# Plotar previsões para cada teste
plt.plot(range(1, len(predictions_4o_mini_test1) + 1), predictions_4o_mini_test1, marker='x', linestyle='--', label='Predicted (Test 1)')
plt.plot(range(1, len(predictions_4o_mini_test2) + 1), predictions_4o_mini_test2, marker='s', linestyle='--', label='Predicted (Test 2)')
plt.plot(range(1, len(predictions_4o_mini_test3) + 1), predictions_4o_mini_test3, marker='d', linestyle='--', label='Predicted (Test 3)')

# Adicionar rótulos e título
plt.title('Actual vs Predicted Ra Values (GPT-4: o1mini)', fontsize=12)
plt.xlabel('Test Case', fontsize=10)
plt.ylabel('Ra (Roughness)', fontsize=10)
plt.xticks(range(1, len(real_values["Ra"]) + 1))
plt.legend(fontsize=8)
plt.grid(True)

# Mostrar o gráfico
plt.tight_layout()
plt.show()

"""**PREVISÕES COM CHAT GPT-4o**"""

import pandas as pd
import numpy as np

# ============================
# Previsões de GPT-4o
# ============================

# **Dados para Previsão (Novos Dados)**
amostra_cc6050 = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39],
    "f": [0.10, 0.10, 0.26, 0.10, 0.16],
    "ap": [0.15, 0.33, 0.24, 0.15, 0.24],
    "Ra": [0.62, 0.72, 1.35, 0.64, 1.12]  # Valores reais de Ra para comparação
})

# Previsões de GPT-4o (três testes diferentes)
predictions_gpt_test1 = [0.709, 0.695, 1.143, 0.516, 1.030]
predictions_gpt_test2 = [0.709, 0.695, 1.143, 0.516, 1.030]
predictions_gpt_test3 = [0.71, 0.69, 1.14, 0.52, 1.03]

# Adicionar previsões ao DataFrame de amostras
amostra_cc6050["Ra_Predicted_Test1"] = predictions_gpt_test1
amostra_cc6050["Ra_Predicted_Test2"] = predictions_gpt_test2
amostra_cc6050["Ra_Predicted_Test3"] = predictions_gpt_test3

# **Imprimir DataFrame com Previsões**
print("\n=== Previsões de GPT-4o ===")
print(amostra_cc6050)

# ============================
# 2. Calcular Métricas
# ============================
def calculate_metrics(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    return mse, rmse, r2

# Calcular métricas para cada teste
mse1, rmse1, r2_1 = calculate_metrics(amostra_cc6050["Ra"], amostra_cc6050["Ra_Predicted_Test1"])
mse2, rmse2, r2_2 = calculate_metrics(amostra_cc6050["Ra"], amostra_cc6050["Ra_Predicted_Test2"])
mse3, rmse3, r2_3 = calculate_metrics(amostra_cc6050["Ra"], amostra_cc6050["Ra_Predicted_Test3"])

# Organizar métricas em um DataFrame
metrics_df = pd.DataFrame({
    "Test": ["Test 1", "Test 2", "Test 3"],
    "MSE": [mse1, mse2, mse3],
    "RMSE": [rmse1, rmse2, rmse3],
    "R²": [r2_1, r2_2, r2_3]
})

# Exibir métricas
print("\n=== Métricas para Cada Teste ===")
print(metrics_df)

# ============================
# 3. Plotar Gráfico
# ============================
plt.figure(figsize=(4, 3))

# Plotar valores reais
plt.plot(range(1, len(amostra_cc6050["Ra"]) + 1), amostra_cc6050["Ra"], marker='o', label='Actual Values', linewidth=2)

# Plotar previsões para cada teste
plt.plot(range(1, len(predictions_gpt_test1) + 1), predictions_gpt_test1, marker='x', linestyle='--', label='Predicted (Test 1)', linewidth=1.5)
plt.plot(range(1, len(predictions_gpt_test2) + 1), predictions_gpt_test2, marker='s', linestyle='--', label='Predicted (Test 2)', linewidth=1.5)
plt.plot(range(1, len(predictions_gpt_test3) + 1), predictions_gpt_test3, marker='d', linestyle='--', label='Predicted (Test 3)', linewidth=1.5)

# Adicionar rótulos e título
plt.title('Actual vs Predicted Ra Values (GPT-4o)', fontsize=12)
plt.xlabel('Test Case', fontsize=10)
plt.ylabel('Ra (Roughness)', fontsize=10)
plt.xticks(range(1, len(amostra_cc6050["Ra"]) + 1))
plt.legend(fontsize=8)
plt.grid(True)

# Mostrar o gráfico
plt.tight_layout()
plt.show()

"""# **MÉTRICAS DAS PREVISÕES**"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# --------------------------------------------------------
# DataFrames de Exemplo
# --------------------------------------------------------

# Dados para ML Models
ml_data = pd.DataFrame({
    'Model': ['DNN', 'Decision \nTree'],
    'MSE': [0.009854, 0.006665],
    'RMSE': [0.099268, 0.081639],
    'R²': [0.885096, 0.922283]
})

# Dados para GPT-4 o1
gpt4_o1_data = pd.DataFrame({
    'Test': ['Test 1', 'Test 2', 'Test 3'],
    'MSE': [0.02334, 0.02738, 0.01360],
    'RMSE': [0.152774, 0.165469, 0.116619],
    'R²': [0.727845, 0.680737, 0.841418]
})

# Dados para GPT-4 o1mini
gpt4_o1mini_data = pd.DataFrame({
    'Test': ['Test 1', 'Test 2', 'Test 3'],
    'MSE': [0.167215, 0.083201, 0.154380],
    'RMSE': [0.408919, 0.288446, 0.392912],
    'R²': [-0.949802, 0.029837, -0.800140]
})

# Dados para GPT-4o
gpt4_o_data = pd.DataFrame({
    'Test': ['Test 1', 'Test 2', 'Test 3'],
    'MSE': [0.014974, 0.014974, 0.015120],
    'RMSE': [0.122369, 0.122369, 0.122963],
    'R²': [0.825394, 0.825394, 0.823694]
})


# --------------------------------------------------------
# Função para plotar as métricas de maneira "limpa"
# --------------------------------------------------------
def plot_metrics(df, x_col, title):
    """
    Plota 3 gráficos (MSE, RMSE, R²) lado a lado, com:
      - Eixo X mostrando apenas as categorias (Model ou Test).
      - Eixo Y mostrando apenas os valores numéricos (sem label de eixo).
      - Título do subplot sendo apenas o nome da métrica.
      - Título global opcional (suptitle).
    """
    metrics = ['MSE', 'RMSE', 'R²']
    fig, axes = plt.subplots(1, 3, figsize=(5.5, 3))

    for i, metric in enumerate(metrics):
        # Plot de barras
        sns.barplot(ax=axes[i], data=df, x=x_col, y=metric, palette='Blues')

        # Título do subplot => nome da métrica
        axes[i].set_title(metric, fontsize=14)

        # Remove o label dos eixos X e Y (mantém apenas ticks com valores)
        axes[i].set_xlabel('')
        axes[i].set_ylabel('')

        # Ajusta tamanho da fonte dos ticks
        axes[i].tick_params(axis='x', labelsize=10, rotation=0)  # rotação se necessário
        axes[i].tick_params(axis='y', labelsize=10)

    # Se quiser, pode exibir um título global para o conjunto de gráficos
    fig.suptitle(title, fontsize=14)

    plt.tight_layout()
    plt.show()


# --------------------------------------------------------
# Exemplos de Uso
# --------------------------------------------------------

plot_metrics(ml_data, 'Model', 'Actual vs Predicted Ra Values (ML Models)')
plot_metrics(gpt4_o1_data, 'Test', 'Actual vs Predicted Ra Values (GPT-4 o1)')
plot_metrics(gpt4_o1mini_data, 'Test', 'Actual vs Predicted Ra Values (GPT-4 o1mini)')
plot_metrics(gpt4_o_data, 'Test', 'Actual vs Predicted Ra Values (GPT-4o)')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Exemplo com apenas ML Models
df = pd.DataFrame({
    'Model': ['DNN', 'Decision Tree', 'GPT-4o1', 'GPT-4o1mini', 'GPT-4o'],
    'MSE':   [0.009854, 0.006665, 0.02334, 0.167215, 0.014974],
    'RMSE':  [0.099268, 0.081639, 0.152774, 0.408919, 0.122369],
    'R²':    [0.885096, 0.922283, 0.727845, -0.949802, 0.825394]
})


def plot_three_radar_charts(df, title='Comparação de Modelos'):
    """
    Cria três gráficos de radar, um para cada métrica (MSE, RMSE, R²),
    e plota todos os modelos do DataFrame distribuídos no círculo,
    conectando-os em um único polígono (por métrica).
    """
    # Métricas que queremos plotar
    metrics = ['MSE', 'RMSE', 'R²']

    # Cria figura com 3 subplots do tipo "polar"
    fig, axes = plt.subplots(1, 3, subplot_kw=dict(polar=True), figsize=(18, 6))
    fig.suptitle(title, fontsize=16, fontweight='bold')

    # Lista de modelos para posicionar ao redor do radar
    models = df['Model'].values
    n_models = len(models)

    # Angulações (em radianos) igualmente espaçadas para cada modelo
    angles = np.linspace(0, 2 * np.pi, n_models, endpoint=False)

    for i, metric in enumerate(metrics):
        # Copia os arrays de ângulo e valores para "fechar" o polígono
        angles_metric = np.concatenate((angles, [angles[0]]))
        values = np.concatenate((df[metric].values, [df[metric].values[0]]))

        # Plot no eixo atual
        ax = axes[i]
        ax.plot(angles_metric, values, marker='o')
        ax.fill(angles_metric, values, alpha=0.25)

        # Define rótulos do eixo "theta" (ângulo) como o nome de cada modelo
        ax.set_xticks(angles)
        ax.set_xticklabels(models)
        ax.set_title(metric, fontweight='bold')

        # Ajusta limite radial para ficar mais agradável (opcional)
        # Exemplo: expandir 10% acima do valor máximo
        ax.set_ylim([0, max(values) * 1.1])

    plt.tight_layout()
    plt.show()

# Uso da função: três radars, cada um para MSE, RMSE e R²
plot_three_radar_charts(ml_data, title='Radar Charts - ML Models')









!pip install catboost

!pip install scikeras



"""**CC6050**"""

import pandas as pd
from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, make_scorer
from catboost import CatBoostRegressor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input # Import the Input layer
from scikeras.wrappers import KerasRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# Filtrar dados da ferramenta CC6050
X_cc6050 = df_cc6050[["Vc", "f", "ap"]]
y_ra_cc6050 = df_cc6050["Ra"]
y_kp_cc6050 = df_cc6050["Kp"]

# Função para construir o modelo DNN
def build_dnn(optimizer='adam'):
    model = Sequential([
        Input(shape=(X_cc6050.shape[1],)),
        Dense(64, activation='relu'),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer=optimizer, loss='mse')
    return model

# Pipeline e GridSearch para Ra - CC6050
pipeline_dnn_ra = Pipeline([
    ('scaler', StandardScaler()),
    ('dnn', KerasRegressor(model=build_dnn, verbose=0))
])

dnn_params_ra = {
    'dnn__epochs': [50],
    'dnn__batch_size': [4, 8],
    'dnn__optimizer': ['adam', 'sgd']
}

grid_dnn_ra = GridSearchCV(pipeline_dnn_ra, param_grid=dnn_params_ra, scoring='neg_mean_squared_error', cv=5)
grid_dnn_ra.fit(X_cc6050, y_ra_cc6050)

# Avaliar o modelo DNN - Ra
best_model_ra = grid_dnn_ra.best_estimator_
y_pred_ra = best_model_ra.predict(X_cc6050)
r2_ra = r2_score(y_ra_cc6050, y_pred_ra)

print(f"CC6050 - Best Params (Ra): {grid_dnn_ra.best_params_}")
print(f"CC6050 - Best MSE (Ra): {-grid_dnn_ra.best_score_}")
print(f"CC6050 - R² (Ra): {r2_ra}")

# Pipeline e GridSearch para Kp - CC6050
pipeline_dnn_kp = Pipeline([
    ('scaler', StandardScaler()),
    ('dnn', KerasRegressor(model=build_dnn, verbose=0))
])

dnn_params_kp = {
    'dnn__epochs': [50],
    'dnn__batch_size': [4, 8],
    'dnn__optimizer': ['adam', 'sgd']
}

grid_dnn_kp = GridSearchCV(pipeline_dnn_kp, param_grid=dnn_params_kp, scoring='neg_mean_squared_error', cv=5)
grid_dnn_kp.fit(X_cc6050, y_kp_cc6050)

# Avaliar o modelo DNN - Kp
best_model_kp = grid_dnn_kp.best_estimator_
y_pred_kp = best_model_kp.predict(X_cc6050)
r2_kp = r2_score(y_kp_cc6050, y_pred_kp)

print(f"CC6050 - Best Params (Kp): {grid_dnn_kp.best_params_}")
print(f"CC6050 - Best MSE (Kp): {-grid_dnn_kp.best_score_}")
print(f"CC6050 - R² (Kp): {r2_kp}")



"""**PCBN 7025**"""

# Filtrar dados da ferramenta PCBN7025
X_pcbn7025 = df_pcbn7025[["Vc", "f", "ap"]]
y_ra_pcbn7025 = df_pcbn7025["Ra"]
y_kp_pcbn7025 = df_pcbn7025["Kp"]

# Função para construir o modelo DNN
def build_dnn(optimizer='adam'):
    model = Sequential([
        Input(shape=(X_pcbn7025.shape[1],)),
        Dense(64, activation='relu'),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer=optimizer, loss='mse')
    return model

# Pipeline e GridSearch para Ra - PCBN7025
pipeline_dnn_ra = Pipeline([
    ('scaler', StandardScaler()),
    ('dnn', KerasRegressor(model=build_dnn, verbose=0))
])

dnn_params_ra = {
    'dnn__epochs': [50],
    'dnn__batch_size': [4, 8],
    'dnn__optimizer': ['adam', 'sgd']
}

grid_dnn_ra = GridSearchCV(pipeline_dnn_ra, param_grid=dnn_params_ra, scoring='neg_mean_squared_error', cv=5)
grid_dnn_ra.fit(X_pcbn7025, y_ra_pcbn7025)

# Avaliar o modelo DNN - Ra
best_model_ra = grid_dnn_ra.best_estimator_
y_pred_ra = best_model_ra.predict(X_pcbn7025)
r2_ra = r2_score(y_ra_pcbn7025, y_pred_ra)

print(f"PCBN7025 - Best Params (Ra): {grid_dnn_ra.best_params_}")
print(f"PCBN7025 - Best MSE (Ra): {-grid_dnn_ra.best_score_}")
print(f"PCBN7025 - R² (Ra): {r2_ra}")

# Pipeline e GridSearch para Kp - PCBN7025
pipeline_dnn_kp = Pipeline([
    ('scaler', StandardScaler()),
    ('dnn', KerasRegressor(model=build_dnn, verbose=0))
])

dnn_params_kp = {
    'dnn__epochs': [50],
    'dnn__batch_size': [4, 8],
    'dnn__optimizer': ['adam', 'sgd']
}

grid_dnn_kp = GridSearchCV(pipeline_dnn_kp, param_grid=dnn_params_kp, scoring='neg_mean_squared_error', cv=5)
grid_dnn_kp.fit(X_pcbn7025, y_kp_pcbn7025)

# Avaliar o modelo DNN - Kp
best_model_kp = grid_dnn_kp.best_estimator_
y_pred_kp = best_model_kp.predict(X_pcbn7025)
r2_kp = r2_score(y_kp_pcbn7025, y_pred_kp)

print(f"PCBN7025 - Best Params (Kp): {grid_dnn_kp.best_params_}")
print(f"PCBN7025 - Best MSE (Kp): {-grid_dnn_kp.best_score_}")
print(f"PCBN7025 - R² (Kp): {r2_kp}")

"""**PREVISÕES CC6050**"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from scikeras.wrappers import KerasRegressor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input

# Dados para previsão
amostra_cc6050 = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39],
    "f": [0.10, 0.10, 0.26, 0.10, 0.16],
    "ap": [0.15, 0.33, 0.24, 0.15, 0.24],
    "Ra": [0.62, 0.72, 1.35, 0.64, 1.12],  # Valores reais de Ra para comparação
    "Kp": [2.46, 1.76, 1.43, 1.52, 3.18]   # Valores reais de Kp para comparação
})

# Separar entrada (X) e saídas reais (y)
X_new = amostra_cc6050[["Vc", "f", "ap"]]
y_true_ra = amostra_cc6050["Ra"]
y_true_kp = amostra_cc6050["Kp"]

# Função para construir o modelo DNN
def build_dnn(optimizer='adam'):
    model = Sequential([
        Input(shape=(X_new.shape[1],)),
        Dense(64, activation='relu'),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer=optimizer, loss='mse')
    return model

# Pipeline e GridSearch para Ra
pipeline_dnn_ra = Pipeline([
    ('scaler', StandardScaler()),
    ('dnn', KerasRegressor(model=build_dnn, verbose=0))
])

dnn_params_ra = {
    'dnn__epochs': [50, 100],
    'dnn__batch_size': [4, 8],
    'dnn__optimizer': ['adam', 'sgd']
}

grid_dnn_ra = GridSearchCV(pipeline_dnn_ra, param_grid=dnn_params_ra, scoring='neg_mean_squared_error', cv=5)
grid_dnn_ra.fit(X_new, y_true_ra)

# Obter o melhor modelo para Ra
best_model_ra = grid_dnn_ra.best_estimator_
y_pred_ra = best_model_ra.predict(X_new)

# Métricas para Ra
mse_ra = mean_squared_error(y_true_ra, y_pred_ra)
r2_ra = r2_score(y_true_ra, y_pred_ra)

print(f"Melhores hiperparâmetros para Ra: {grid_dnn_ra.best_params_}")
print(f"MSE para Ra: {mse_ra:.4f}, R²: {r2_ra:.4f}")

# Pipeline e GridSearch para Kp
pipeline_dnn_kp = Pipeline([
    ('scaler', StandardScaler()),
    ('dnn', KerasRegressor(model=build_dnn, verbose=0))
])

dnn_params_kp = {
    'dnn__epochs': [50, 100],
    'dnn__batch_size': [4, 8],
    'dnn__optimizer': ['adam', 'sgd']
}

grid_dnn_kp = GridSearchCV(pipeline_dnn_kp, param_grid=dnn_params_kp, scoring='neg_mean_squared_error', cv=5)
grid_dnn_kp.fit(X_new, y_true_kp)

# Obter o melhor modelo para Kp
best_model_kp = grid_dnn_kp.best_estimator_
y_pred_kp = best_model_kp.predict(X_new)

# Métricas para Kp
mse_kp = mean_squared_error(y_true_kp, y_pred_kp)
r2_kp = r2_score(y_true_kp, y_pred_kp)

print(f"Melhores hiperparâmetros para Kp: {grid_dnn_kp.best_params_}")
print(f"MSE para Kp: {mse_kp:.4f}, R²: {r2_kp:.4f}")

# Plotar gráfico para Ra
plt.figure(figsize=(6, 4))
plt.plot(range(1, len(y_true_ra) + 1), y_true_ra, marker='o', label='True Ra')
plt.plot(range(1, len(y_pred_ra) + 1), y_pred_ra, marker='x', label='Predicted Ra')
plt.title('Previsão de Ra')
plt.xlabel('Teste')
plt.ylabel('Ra')
plt.xticks(range(1, len(y_true_ra) + 1))  # Números dos testes
plt.legend()
plt.grid()
plt.show()

# Plotar gráfico para Kp
plt.figure(figsize=(6, 4))
plt.plot(range(1, len(y_true_kp) + 1), y_true_kp, marker='o', label='True Kp')
plt.plot(range(1, len(y_pred_kp) + 1), y_pred_kp, marker='x', label='Predicted Kp')
plt.title('Previsão de Kp')
plt.xlabel('Teste')
plt.ylabel('Kp')
plt.xticks(range(1, len(y_true_kp) + 1))  # Números dos testes
plt.legend()
plt.grid()
plt.show()

# Plotar gráfico para Ra
plt.figure(figsize=(6, 4))
plt.plot(range(1, len(y_true_ra) + 1), y_true_ra, marker='o', label='True Ra')
plt.plot(range(1, len(y_pred_ra) + 1), y_pred_ra, marker='x', label='Predicted Ra')
plt.title('Previsão de Ra')
plt.xlabel('Teste')
plt.ylabel('Ra')
plt.xticks(range(1, len(y_true_ra) + 1))  # Números dos testes
plt.legend()
plt.grid()
plt.show()

# Plotar gráfico para Kp
plt.figure(figsize=(6, 4))
plt.plot(range(1, len(y_true_kp) + 1), y_true_kp, marker='o', label='True Kp')
plt.plot(range(1, len(y_pred_kp) + 1), y_pred_kp, marker='x', label='Predicted Kp')
plt.title('Previsão de Kp')
plt.xlabel('Teste')
plt.ylabel('Kp')
plt.xticks(range(1, len(y_true_kp) + 1))  # Números dos testes
plt.legend()
plt.grid()
plt.show()

# Criar tabela com resultados
resultados = pd.DataFrame({
    "Teste": range(1, len(y_true_ra) + 1),
    "Vc": X_new["Vc"],
    "f": X_new["f"],
    "ap": X_new["ap"],
    "Ra Real": y_true_ra,
    "Ra Previsto": y_pred_ra,
    "Kp Real": y_true_kp,
    "Kp Previsto": y_pred_kp
})

# Exibir tabela
print(resultados)

# Salvar tabela em CSV (opcional)
resultados.to_csv("resultados_previsao_cc6050.csv", index=False)

"""**PREVISÕES PCBN 7025**




"""

# Dados para previsão (PCBN7025)
amostra_pcbn7025 = pd.DataFrame({
    "Vc": [100.00, 225.00, 162.50, 225.00, 57.39],
    "f": [0.10, 0.10, 0.26, 0.22, 0.16],
    "ap": [0.15, 0.33, 0.24, 0.15, 0.24],
    "Ra": [0.62, 0.72, 1.20, 2.15, 0.67],  # Valores reais de Ra
    "Kp": [3.66, 2.33, 2.58, 2.17, 5.51]   # Valores reais de Kp
})

# Separar entrada (X) e saídas reais (y)
X_new = amostra_pcbn7025[["Vc", "f", "ap"]]
y_true_ra = amostra_pcbn7025["Ra"]
y_true_kp = amostra_pcbn7025["Kp"]

# Função para construir o modelo DNN
def build_dnn(optimizer='adam'):
    model = Sequential([
        Input(shape=(X_new.shape[1],)),
        Dense(64, activation='relu'),
        Dense(32, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer=optimizer, loss='mse')
    return model

# Pipeline e GridSearch para Ra
pipeline_dnn_ra = Pipeline([
    ('scaler', StandardScaler()),
    ('dnn', KerasRegressor(model=build_dnn, verbose=0))
])

dnn_params_ra = {
    'dnn__epochs': [50, 100],
    'dnn__batch_size': [4, 8],
    'dnn__optimizer': ['adam', 'sgd']
}

grid_dnn_ra = GridSearchCV(pipeline_dnn_ra, param_grid=dnn_params_ra, scoring='neg_mean_squared_error', cv=5)
grid_dnn_ra.fit(X_new, y_true_ra)

# Obter o melhor modelo para Ra
best_model_ra = grid_dnn_ra.best_estimator_
y_pred_ra = best_model_ra.predict(X_new)

# Métricas para Ra
mse_ra = mean_squared_error(y_true_ra, y_pred_ra)
r2_ra = r2_score(y_true_ra, y_pred_ra)

print(f"Melhores hiperparâmetros para Ra: {grid_dnn_ra.best_params_}")
print(f"MSE para Ra: {mse_ra:.4f}, R²: {r2_ra:.4f}")

# Pipeline e GridSearch para Kp
pipeline_dnn_kp = Pipeline([
    ('scaler', StandardScaler()),
    ('dnn', KerasRegressor(model=build_dnn, verbose=0))
])

dnn_params_kp = {
    'dnn__epochs': [50, 100],
    'dnn__batch_size': [4, 8],
    'dnn__optimizer': ['adam', 'sgd']
}

grid_dnn_kp = GridSearchCV(pipeline_dnn_kp, param_grid=dnn_params_kp, scoring='neg_mean_squared_error', cv=5)
grid_dnn_kp.fit(X_new, y_true_kp)

# Obter o melhor modelo para Kp
best_model_kp = grid_dnn_kp.best_estimator_
y_pred_kp = best_model_kp.predict(X_new)

# Métricas para Kp
mse_kp = mean_squared_error(y_true_kp, y_pred_kp)
r2_kp = r2_score(y_true_kp, y_pred_kp)

print(f"Melhores hiperparâmetros para Kp: {grid_dnn_kp.best_params_}")
print(f"MSE para Kp: {mse_kp:.4f}, R²: {r2_kp:.4f}")

# Plotar gráfico para Ra
plt.figure(figsize=(6, 4))
plt.plot(range(1, len(y_true_ra) + 1), y_true_ra, marker='o', label='True Ra')
plt.plot(range(1, len(y_pred_ra) + 1), y_pred_ra, marker='x', label='Predicted Ra')
plt.title('Previsão de Ra - PCBN7025')
plt.xlabel('Teste')
plt.ylabel('Ra')
plt.xticks(range(1, len(y_true_ra) + 1))  # Números dos testes
plt.legend()
plt.grid()
plt.show()

# Plotar gráfico para Kp
plt.figure(figsize=(6, 4))
plt.plot(range(1, len(y_true_kp) + 1), y_true_kp, marker='o', label='True Kp')
plt.plot(range(1, len(y_pred_kp) + 1), y_pred_kp, marker='x', label='Predicted Kp')
plt.title('Previsão de Kp - PCBN7025')
plt.xlabel('Teste')
plt.ylabel('Kp')
plt.xticks(range(1, len(y_true_kp) + 1))  # Números dos testes
plt.legend()
plt.grid()
plt.show()

# Criar tabela com resultados
resultados = pd.DataFrame({
    "Teste": range(1, len(y_true_ra) + 1),
    "Vc": X_new["Vc"],
    "f": X_new["f"],
    "ap": X_new["ap"],
    "Ra Real": y_true_ra,
    "Ra Previsto": y_pred_ra,
    "Kp Real": y_true_kp,
    "Kp Previsto": y_pred_kp
})

# Exibir tabela
print(resultados)

# Salvar tabela em CSV (opcional)
resultados.to_csv("resultados_previsao_pcbn7025.csv", index=False)











dados_CC6050W.info()

dados_PCBN

!pip install ace_tools

# Adding the "Tool" column
dados_CC6050W["Tool"] = "CC6050W"
dados_PCBN["Tool"] = "PCBN_7025W"

# Concatenating the dataframes
df_combined = pd.concat([dados_CC6050W, dados_PCBN], ignore_index=True)

# Combinando os dataframes
df_combined = pd.concat([dados_CC6050W, dados_PCBN], ignore_index=True)

# Exibindo o dataset combinado
print(df_combined)

# Instalar uma fonte similar à Times New Roman
!apt-get install -y fonts-liberation

# Configurar o matplotlib para usar a fonte Liberation Serif, que é similar à Times New Roman
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# Carregar a fonte instalada
font_path = '/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf'
fm.fontManager.addfont(font_path)
plt.rcParams['font.family'] = 'Liberation Serif'

df_combined.info()

# Calcular as estatísticas descritivas para T e SPL por ferramenta
descriptive_stats = df_combined.groupby('Tool')[['T', 'SPL']].describe().unstack().reset_index()

# Selecionar apenas as métricas desejadas
metrics = descriptive_stats[descriptive_stats['level_1'].isin(['mean', 'std', 'min', '25%', '50%', '75%', 'max'])]

# Exibir a tabela de estatísticas descritivas
print(metrics)

import pandas as pd

# Dados conforme a descrição fornecida
data = {
    'level_0': ['T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL', 'SPL'],
    'level_1': ['mean', 'mean', 'std', 'std', 'min', 'min', '25%', '25%', '50%', '50%', '75%', '75%', 'max', 'max', 'mean', 'mean', 'std', 'std', 'min', 'min', '25%', '25%', '50%', '50%', '75%', '75%', 'max', 'max'],
    'Tool': ['CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W', 'CC6050W', 'PCBN_7025W'],
    0: [43.802632, 47.276316, 11.204717, 12.008358, 24.5, 28.25, 36.0, 38.75, 44.0, 46.5, 51.5, 54.75, 63.0, 70.0, 81.377368, 82.474211, 7.731284, 8.495464, 64.39, 65.5, 77.595, 79.915, 83.26, 83.57, 85.59, 87.54, 95.44, 98.79]
}

df_stats = pd.DataFrame(data)

# Pivotar a tabela para o formato desejado
df_pivot = df_stats.pivot_table(index=['level_1'], columns=['level_0', 'Tool'], values=0)

# Ajustar os nomes das colunas
df_pivot.columns = [f'{col[1]} {col[0]}' for col in df_pivot.columns]

# Exibir a tabela de estatísticas descritivas
print(df_pivot)

import seaborn as sns

# Plotar os boxplots
fig, axes = plt.subplots(2, 1, figsize=(3, 5))

# Boxplot para a variável T
sns.boxplot(x='Tool', y='T', data=df_combined, ax=axes[0])
axes[0].set_title('Comparison of T for \n Different Tools',fontsize=14)
axes[0].set_xlabel('Tool')
axes[0].set_ylabel('T')

# Boxplot para a variável SPL
sns.boxplot(x='Tool', y='SPL', data=df_combined, ax=axes[1])
axes[1].set_title('Comparison of SPL for \n Different Tools', fontsize=14)
axes[1].set_xlabel('Tool')
axes[1].set_ylabel('SPL')

plt.tight_layout()
plt.show()

df=df_combined

# Lista de variáveis numéricas
variables = ['T', 'SPL']

# Criar uma figura com subplots, 2 colunas por linha
fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(3, 5))

# Achatando o array de axes para facilitar o acesso
axes = axes.flatten()


# Loop para plotar uma curva de densidade para cada variável
for i, var in enumerate(variables):
    sns.kdeplot(data=df, x=var, hue='Tool', ax=axes[i], fill=True)
    axes[i].set_title(f'Density Plot of {var}\n by Tools', fontsize=14)
    axes[i].set_xlabel(var, fontsize=12)
    axes[i].set_ylabel('Density', fontsize=12)

    # Obter a legenda do gráfico atual
    legend = axes[i].get_legend()

    # Alterar o tamanho da fonte da legenda (por exemplo, para 8)
    if legend:  # Verifica se a legenda existe
        for text in legend.get_texts():
            text.set_fontsize(8)
            # Alinha a legenda à esquerda
        legend._loc = 2  # Código para 'upper left'

# Ajustar o layout para evitar sobreposição
plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Supondo que o dataframe seja df e esteja carregado corretamente
df = df_combined  # Ajuste isso para o nome correto do seu dataframe se necessário

# Lista de variáveis numéricas
variables = ['T', 'SPL']

# Criar uma figura com subplots, 2 colunas por linha
fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(5, 6))

# Achatando o array de axes para facilitar o acesso
axes = axes.flatten()

# Loop para plotar uma curva de densidade para cada variável
for i, var in enumerate(variables):
    plot = sns.kdeplot(data=df, x=var, hue='Tool', ax=axes[i], fill=True)
    axes[i].set_title(f'Density Plot of {var} by Tools')
    plot.set(xlabel=var, ylabel='Density')  # Configurando os rótulos dos eixos em inglês

# Alterando o nome da legenda de 'Ferramentas' para 'Tools'
handles, labels = axes[0].get_legend_handles_labels()
labels = ['Tools' if label == 'Tool' else label for label in labels]
axes[0].legend(handles, labels)

# Ajustar o layout para evitar sobreposição
plt.tight_layout()
plt.show()

from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import numpy as np

# Escolher uma variável para o exemplo
variable = 'T'

# Criar uma figura para o gráfico 3D
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Cores para cada tipo de ferramenta
colors = ['blue', 'green', 'red']
tools = df['Tool'].unique()

# Plotar um histograma para cada tipo de ferramenta
for i, tool in enumerate(tools):
    # Dados para o tipo de ferramenta específico
    data = df[df['Tool'] == tool][variable]

    # Computar histograma
    hist, bins = np.histogram(data, bins=10)

    # Configurar as posições dos bins
    xs = (bins[:-1] + bins[1:]) / 2

    # Desenhar cada barra do histograma
    ax.bar(xs, hist, zs=i, zdir='y', width=(bins[1] - bins[0]), alpha=0.8, color=colors[i])

ax.set_xlabel(variable)
ax.set_ylabel('Ferramentas')
ax.set_zlabel('Frequency')

plt.show()

df_combined.info()

import seaborn as sns
import matplotlib.pyplot as plt

# Calcular a matriz de correlação
numeric_columns = dados_CC6050W.select_dtypes(include=['number'])
correlation_matrix = numeric_columns.corr()

# Definir tamanho da figura
plt.figure(figsize=(4, 2.5))

# Definir tamanho da fonte globalmente
plt.rcParams.update({'font.size': 12})

# Plotar o mapa de calor da matriz de correlação
ax = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws={"size": 12})

# Adicionar título
plt.title('Correlation Matrix - CC6050W', fontsize=14)

# Aumentar a fonte dos rótulos dos eixos X e Y
ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)
ax.set_yticklabels(ax.get_yticklabels(), fontsize=12)

# Exibir o gráfico
plt.show()

# Calcular a matriz de correlação
numeric_columns_2 = dados_PCBN.select_dtypes(include=['number'])
correlation_matrix = numeric_columns_2.corr()

# Definir tamanho da figura
plt.figure(figsize=(4, 2.5))

# Definir tamanho da fonte globalmente
plt.rcParams.update({'font.size': 12})

# Plotar o mapa de calor da matriz de correlação
ax = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws={"size": 12})

# Adicionar título
plt.title('Correlation Matrix - PCBN 7025W', fontsize=14)

# Aumentar a fonte dos rótulos dos eixos X e Y
ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)
ax.set_yticklabels(ax.get_yticklabels(), fontsize=12)

# Exibir o gráfico
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
from math import sqrt

import numpy as np
import matplotlib.pyplot as plt

"""# **PCBN**
Tool life

"""

dados_PCBN

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error
from math import sqrt

# Carregar os dados
data = dados_PCBN  # Certifique-se de que a variável dados_PCBN está definida e contém os dados
X = data.drop(['T', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['T']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar listas para armazenar os resultados
model_names = ['Linear Regression', 'Decision Tree Regression',
               'Random Forest Regression', 'Neural Network Regression (MLP)',
               'Stochastic Gradient Descent (SGD) Regression']
mse_values = []
rmse_values = []
r2_values = []

# Inicializar lista de pipelines
pipelines = [
    Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    Pipeline([('scaler', StandardScaler()), ('decision_tree', DecisionTreeRegressor())]),
    Pipeline([('scaler', StandardScaler()), ('random_forest', RandomForestRegressor())]),
    Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=1000))]),
    Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor())])
]

# Loop através dos pipelines
for pipeline, model_name in zip(pipelines, model_names):
    # Treinar o modelo
    pipeline.fit(X_train, y_train)

    # Fazer previsões
    predictions = pipeline.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = pipeline.score(X_test, y_test)

    # Adicionar métricas à lista
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, make_scorer
from math import sqrt

# Carregar os dados
data = dados_PCBN  # Certifique-se de que a variável dados_PCBN está definida e contém os dados
X = data.drop(['T', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['T']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir os parâmetros para o GridSearchCV
param_grid = {
    'linear_regression': {},
    'decision_tree': {
        'decision_tree__max_depth': [None, 10, 20, 30],
        'decision_tree__min_samples_split': [2, 5, 10],
        'decision_tree__min_samples_leaf': [1, 2, 4]
    },
    'random_forest': {
        'random_forest__n_estimators': [100, 200, 300],
        'random_forest__max_depth': [None, 10, 20, 30],
        'random_forest__min_samples_split': [2, 5, 10],
        'random_forest__min_samples_leaf': [1, 2, 4]
    },
    'mlp_regression': {
        'mlp_regression__hidden_layer_sizes': [(50,), (100,), (100, 50)],
        'mlp_regression__activation': ['tanh', 'relu'],
        'mlp_regression__solver': ['adam', 'sgd'],
        'mlp_regression__max_iter': [500, 1000]
    },
    'sgd_regression': {
        'sgd_regression__penalty': ['l2', 'l1', 'elasticnet'],
        'sgd_regression__alpha': [0.0001, 0.001, 0.01],
        'sgd_regression__max_iter': [1000, 2000]
    }
}

# Inicializar lista de pipelines
pipelines = {
    'linear_regression': Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    'decision_tree': Pipeline([('scaler', StandardScaler()), ('decision_tree', DecisionTreeRegressor())]),
    'random_forest': Pipeline([('scaler', StandardScaler()), ('random_forest', RandomForestRegressor())]),
    'mlp_regression': Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor())]),
    'sgd_regression': Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor())])
}

# Inicializar listas para armazenar os resultados
model_names = []
mse_values = []
rmse_values = []
r2_values = []

# Loop através dos pipelines
for model_name, pipeline in pipelines.items():
    # Configurar o GridSearchCV
    grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    grid_search.fit(X_train, y_train)

    # Fazer previsões
    best_model = grid_search.best_estimator_
    predictions = best_model.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = best_model.score(X_test, y_test)

    # Adicionar métricas à lista
    model_names.append(model_name)
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

results_df

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt
import seaborn as sns

# Definir os parâmetros para o RandomizedSearchCV
param_distributions = {
    'linear_regression': {},
    'sgd_regression': {
        'sgd_regression__penalty': ['l2', 'l1', 'elasticnet'],
        'sgd_regression__alpha': [0.0001, 0.001, 0.01],
        'sgd_regression__max_iter': [1000, 2000]
    }
}

# Inicializar lista de pipelines
pipelines = {
    'linear_regression': Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    'sgd_regression': Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(random_state=42))])
}

# Inicializar listas para armazenar os resultados
model_names = []
mse_values = []
rmse_values = []
r2_values = []
best_models = []

# Loop através dos pipelines
for model_name, pipeline in pipelines.items():
    # Configurar o RandomizedSearchCV
    randomized_search = RandomizedSearchCV(pipeline, param_distributions[model_name], cv=5, scoring='neg_mean_squared_error', n_iter=50, n_jobs=-1, random_state=42)
    randomized_search.fit(X_train, y_train)

    # Obter o melhor modelo
    best_model = randomized_search.best_estimator_
    best_models.append(best_model)

    # Fazer previsões
    predictions = best_model.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, predictions)

    # Adicionar métricas à lista
    model_names.append(model_name)
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

# Criar figuras de subplots
fig, axs = plt.subplots(len(best_models), figsize=(4, 3 * len(best_models)))

# Se apenas um modelo está sendo plotado, transformar axs em uma lista
if len(best_models) == 1:
    axs = [axs]

# Loop para plotar os melhores modelos
for idx, (best_model, model_name) in enumerate(zip(best_models, model_names)):
    # Fazer previsões
    predictions = best_model.predict(X_test)

    # Plotar relação entre previsto e real
    sns.scatterplot(x=y_test, y=predictions, ax=axs[idx], label='Predicted vs Actual')
    axs[idx].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', label='Ideal fit')  # Linha de ajuste ideal
    axs[idx].set_title(f'{model_name}')
    axs[idx].set_xlabel('Actual Values')
    axs[idx].set_ylabel('Predicted Values')
    axs[idx].legend()
    axs[idx].grid(True)  # Adicionando linhas de grade
plt.tight_layout()
plt.show()

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

# Carregar os dados
data = dados_PCBN  # Certifique-se de que a variável dados_PCBN está definida e contém os dados
X = data.drop(['T', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['T']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir os parâmetros para o RandomizedSearchCV
param_distributions = {
    'linear_regression': {},
    'decision_tree': {
        'decision_tree__max_depth': [None, 10, 20, 30],
        'decision_tree__min_samples_split': [2, 5, 10],
        'decision_tree__min_samples_leaf': [1, 2, 4]
    },
    'random_forest': {
        'random_forest__n_estimators': [100, 200, 300],
        'random_forest__max_depth': [None, 10, 20, 30],
        'random_forest__min_samples_split': [2, 5, 10],
        'random_forest__min_samples_leaf': [1, 2, 4]
    },
    'mlp_regression': {
        'mlp_regression__hidden_layer_sizes': [(50,), (100,), (100, 50)],
        'mlp_regression__activation': ['tanh', 'relu'],
        'mlp_regression__solver': ['adam', 'sgd'],
        'mlp_regression__max_iter': [500, 1000]
    },
    'sgd_regression': {
        'sgd_regression__penalty': ['l2', 'l1', 'elasticnet'],
        'sgd_regression__alpha': [0.0001, 0.001, 0.01],
        'sgd_regression__max_iter': [1000, 2000]
    }
}

# Inicializar lista de pipelines
pipelines = {
    'linear_regression': Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    'decision_tree': Pipeline([('scaler', StandardScaler()), ('decision_tree', DecisionTreeRegressor())]),
    'random_forest': Pipeline([('scaler', StandardScaler()), ('random_forest', RandomForestRegressor())]),
    'mlp_regression': Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(random_state=42))]),
    'sgd_regression': Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(random_state=42))])
}

# Inicializar listas para armazenar os melhores hiperparâmetros
best_params_list = []
model_names = []

# Loop através dos pipelines
for model_name, pipeline in pipelines.items():
    # Configurar o RandomizedSearchCV
    randomized_search = RandomizedSearchCV(pipeline, param_distributions[model_name], cv=5, scoring='neg_mean_squared_error', n_iter=50, n_jobs=-1, random_state=42)
    randomized_search.fit(X_train, y_train)

    # Obter os melhores hiperparâmetros
    best_params = randomized_search.best_params_
    best_params_list.append(best_params)
    model_names.append(model_name)

# Criar dataframe com os melhores hiperparâmetros
best_params_df = pd.DataFrame(best_params_list, index=model_names)

# Exibir os melhores hiperparâmetros
print(best_params_df)

# Plotar os melhores hiperparâmetros
fig, ax = plt.subplots(figsize=(10, 6))
ax.axis('tight')
ax.axis('off')
table = ax.table(cellText=best_params_df.values, colLabels=best_params_df.columns, rowLabels=best_params_df.index, cellLoc='center', loc='center')
table.auto_set_font_size(False)
table.set_fontsize(10)
table.scale(1.2, 1.2)
plt.title('Best Hyperparameters for Each Model')
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt
import seaborn as sns

# Supondo que 'dados_PCBN' é um DataFrame do Pandas já carregado com os dados
# Certifique-se de que a variável dados_PCBN está definida e contém os dados
data = dados_PCBN
X = data.drop(['T', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['T']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar listas para armazenar os resultados
model_names = ['Neural Network Regression (MLP)', 'Stochastic Gradient Descent (SGD) Regression']
mse_values = []
rmse_values = []
r2_values = []

# Inicializar lista de pipelines
pipelines = [
    Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=1000, random_state=42))]),
    Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(max_iter=1000, random_state=42))])
]

# Criar figuras de subplots
fig, axs = plt.subplots(len(pipelines), figsize=(5, 3 * len(pipelines)))

# Se apenas um modelo está sendo plotado, transformar axs em uma lista
if len(pipelines) == 1:
    axs = [axs]

# Loop através dos pipelines
for idx, (pipeline, model_name) in enumerate(zip(pipelines, model_names)):
    # Treinar o modelo
    pipeline.fit(X_train, y_train)

    # Fazer previsões
    predictions = pipeline.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, predictions)

    # Adicionar métricas à lista
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

    # Plotar relação entre previsto e real
    sns.scatterplot(x=y_test, y=predictions, ax=axs[idx], label='Predicted vs Actual')
    axs[idx].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', label='Ideal fit')  # Linha de ajuste ideal
    axs[idx].set_title(f'{model_name}')
    axs[idx].set_xlabel('Actual Values')
    axs[idx].set_ylabel('Predicted Values')
    axs[idx].legend()
    axs[idx].grid(True)  # Adicionando linhas de grade
plt.tight_layout()
plt.show()

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt
import seaborn as sns

# Carregar os dados
data = dados_PCBN  # Garanta que 'dados_PCBN' contém o DataFrame acima mencionado
X = data.drop(['T', 'Tool'], axis=1)  # Variáveis preditoras
y = data['T']  # Variável de saída

# Dividir os dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar pipelines
pipelines = [
    Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=1000, random_state=42))]),
    Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(max_iter=1000, random_state=42))])
]

# Nomes dos modelos
model_names = ['Neural Network Regression (MLP)', 'Stochastic Gradient Descent (SGD) Regression']

# Criar figuras de subplots
fig, axs = plt.subplots(len(pipelines), figsize=(10, 6 * len(pipelines)))

# Assegurar que axs seja iterável
if len(pipelines) == 1:
    axs = [axs]

# Loop através dos pipelines
for idx, (pipeline, model_name) in enumerate(zip(pipelines, model_names)):
    # Treinar o modelo
    pipeline.fit(X_train, y_train)

    # Fazer previsões
    predictions = pipeline.predict(X_test)

    # Obter coeficientes para modelos lineares
    equation = ""
    if 'sgd_regression' in pipeline.named_steps:
        coef = pipeline.named_steps['sgd_regression'].coef_
        intercept = pipeline.named_steps['sgd_regression'].intercept_
        terms = [f"{coef[i]:.2f}*{X.columns[i]}" for i in range(len(coef))]
        equation = f"y = {intercept[0]:.2f} + {' + '.join(terms)}"

    # Plotar relação entre previsto e real
    sns.scatterplot(x=y_test, y=predictions, ax=axs[idx], label='Predicted vs Actual')
    axs[idx].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', label='Ideal fit')
    axs[idx].set_title(f'{model_name}')
    axs[idx].set_xlabel('Actual Values')
    axs[idx].set_ylabel('Predicted Values')
    axs[idx].legend()
    axs[idx].grid(True)

    # Exibir a equação da reta para modelos lineares
    if equation:
        plt.figtext(0.5, 0.01 * (idx + 1), equation, ha='center', fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.show()

# Calculando métricas
mse = [mean_squared_error(y_test, pipeline.predict(X_test)) for pipeline in pipelines]
rmse = [sqrt(m) for m in mse]
r2 = [r2_score(y_test, pipeline.predict(X_test)) for pipeline in pipelines]

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse,
    'Root Mean Squared Error (RMSE)': rmse,
    'R² (Coefficient of Determination)': r2
})

# Exibir os resultados
print(results_df)



from math import sqrt
import statsmodels.api as sm
from scipy import stats

# Loop através dos pipelines
for pipeline, model_name in zip(pipelines, model_names):
    # Treinar o modelo
    pipeline.fit(X_train, y_train)

    # Fazer previsões
    predictions = pipeline.predict(X_test)

    # Resíduos
    residuals = y_test - predictions

    # Análise dos resíduos
    print(f"Análise de Resíduos para o Modelo: {model_name}")
    sm.qqplot(residuals, line ='45')
    plt.title("Q-Q Plot dos Resíduos")
    plt.show()

    # Teste de Bartlett
    bartlett_test = stats.bartlett(predictions, residuals)
    print(f"Resultado do Teste de Bartlett para o Modelo {model_name}:")
    print("Estatística de teste:", bartlett_test[0])
    print("p-value:", bartlett_test[1])

    # Teste de Shapiro-Wilk
    shapiro_test = stats.shapiro(residuals)
    print(f"\nResultado do Teste de Shapiro-Wilk para o Modelo {model_name}:")
    print("Estatística de teste:", shapiro_test[0])
    print("p-value:", shapiro_test[1])
    print("-------------------------------------------------------------------")

"""# **6050W**
Tool life
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt

# Carregar os dados
data = dados_CC6050W  # Certifique-se de que a variável dados_CC6050W está definida e contém os dados
X = data.drop(['T', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['T']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir os parâmetros para o GridSearchCV
param_grid = {
    'linear_regression': {},
    'decision_tree': {
        'decision_tree__max_depth': [None, 10, 20, 30],
        'decision_tree__min_samples_split': [2, 5, 10],
        'decision_tree__min_samples_leaf': [1, 2, 4]
    },
    'random_forest': {
        'random_forest__n_estimators': [100, 200, 300],
        'random_forest__max_depth': [None, 10, 20, 30],
        'random_forest__min_samples_split': [2, 5, 10],
        'random_forest__min_samples_leaf': [1, 2, 4]
    },
    'mlp_regression': {
        'mlp_regression__hidden_layer_sizes': [(50,), (100,), (100, 50)],
        'mlp_regression__activation': ['tanh', 'relu'],
        'mlp_regression__solver': ['adam', 'sgd'],
        'mlp_regression__max_iter': [500, 1000]
    },
    'sgd_regression': {
        'sgd_regression__penalty': ['l2', 'l1', 'elasticnet'],
        'sgd_regression__alpha': [0.0001, 0.001, 0.01],
        'sgd_regression__max_iter': [1000, 2000]
    }
}

# Inicializar lista de pipelines
pipelines = {
    'linear_regression': Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    'decision_tree': Pipeline([('scaler', StandardScaler()), ('decision_tree', DecisionTreeRegressor())]),
    'random_forest': Pipeline([('scaler', StandardScaler()), ('random_forest', RandomForestRegressor())]),
    'mlp_regression': Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(random_state=42))]),
    'sgd_regression': Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(random_state=42))])
}

# Inicializar listas para armazenar os resultados
model_names = []
mse_values = []
rmse_values = []
r2_values = []
best_params_list = []

# Loop através dos pipelines
for model_name, pipeline in pipelines.items():
    # Configurar o GridSearchCV
    grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    grid_search.fit(X_train, y_train)

    # Obter o melhor modelo e os melhores hiperparâmetros
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_
    best_params_list.append(best_params)

    # Fazer previsões
    predictions = best_model.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, predictions)

    # Adicionar métricas à lista
    model_names.append(model_name)
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

# Criar dataframe com os melhores hiperparâmetros
best_params_df = pd.DataFrame(best_params_list, index=model_names)

# Exibir os melhores hiperparâmetros
print(best_params_df)

# Plotar as métricas de desempenho
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Model Performance Metrics')
results_df.plot(kind='bar', x='Model', y=['Mean Squared Error (MSE)', 'Root Mean Squared Error (RMSE)', 'R² (Coefficient of Determination)'], ax=plt.gca())
plt.xticks(rotation=45)
plt.tight_layout()

results_df

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt
import seaborn as sns

# Supondo que 'dados_PCBN' é um DataFrame do Pandas já carregado com os dados
# Certifique-se de que a variável dados_PCBN está definida e contém os dados
data = dados_CC6050W
X = data.drop(['T', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['T']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar listas para armazenar os resultados
model_names = ['Neural Network Regression (MLP)', 'Stochastic Gradient Descent (SGD) Regression']
mse_values = []
rmse_values = []
r2_values = []

# Inicializar lista de pipelines
pipelines = [
    Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=1000, random_state=42))]),
    Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(max_iter=1000, random_state=42))])
]

# Criar figuras de subplots
fig, axs = plt.subplots(len(pipelines), figsize=(5, 3 * len(pipelines)))

# Se apenas um modelo está sendo plotado, transformar axs em uma lista
if len(pipelines) == 1:
    axs = [axs]

# Loop através dos pipelines
for idx, (pipeline, model_name) in enumerate(zip(pipelines, model_names)):
    # Treinar o modelo
    pipeline.fit(X_train, y_train)

    # Fazer previsões
    predictions = pipeline.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, predictions)

    # Adicionar métricas à lista
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

    # Plotar relação entre previsto e real
    sns.scatterplot(x=y_test, y=predictions, ax=axs[idx], label='Predicted vs Actual')
    axs[idx].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', label='Ideal fit')  # Linha de ajuste ideal
    axs[idx].set_title(f'{model_name}')
    axs[idx].set_xlabel('Actual Values')
    axs[idx].set_ylabel('Predicted Values')
    axs[idx].legend()
    axs[idx].grid(True)  # Adicionando linhas de grade
plt.tight_layout()
plt.show()

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

"""# **SPL**

# **CC6050W**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt

# Carregar os dados
data = dados_CC6050W  # Certifique-se de que a variável dados_CC6050W está definida e contém os dados
X = data.drop(['SPL', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['SPL']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir os parâmetros para o GridSearchCV
param_grid = {
    'linear_regression': {},
    'decision_tree': {
        'decision_tree__max_depth': [None, 10, 20, 30],
        'decision_tree__min_samples_split': [2, 5, 10],
        'decision_tree__min_samples_leaf': [1, 2, 4]
    },
    'random_forest': {
        'random_forest__n_estimators': [100, 200, 300],
        'random_forest__max_depth': [None, 10, 20, 30],
        'random_forest__min_samples_split': [2, 5, 10],
        'random_forest__min_samples_leaf': [1, 2, 4]
    },
    'mlp_regression': {
        'mlp_regression__hidden_layer_sizes': [(50,), (100,), (100, 50)],
        'mlp_regression__activation': ['tanh', 'relu'],
        'mlp_regression__solver': ['adam', 'sgd'],
        'mlp_regression__max_iter': [500, 1000]
    },
    'sgd_regression': {
        'sgd_regression__penalty': ['l2', 'l1', 'elasticnet'],
        'sgd_regression__alpha': [0.0001, 0.001, 0.01],
        'sgd_regression__max_iter': [1000, 2000]
    }
}

# Inicializar lista de pipelines
pipelines = {
    'linear_regression': Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    'decision_tree': Pipeline([('scaler', StandardScaler()), ('decision_tree', DecisionTreeRegressor())]),
    'random_forest': Pipeline([('scaler', StandardScaler()), ('random_forest', RandomForestRegressor())]),
    'mlp_regression': Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(random_state=42))]),
    'sgd_regression': Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(random_state=42))])
}

# Inicializar listas para armazenar os resultados
model_names = []
mse_values = []
rmse_values = []
r2_values = []
best_params_list = []

# Loop através dos pipelines
for model_name, pipeline in pipelines.items():
    # Configurar o GridSearchCV
    grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    grid_search.fit(X_train, y_train)

    # Obter o melhor modelo e os melhores hiperparâmetros
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_
    best_params_list.append(best_params)

    # Fazer previsões
    predictions = best_model.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, predictions)

    # Adicionar métricas à lista
    model_names.append(model_name)
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

# Criar dataframe com os melhores hiperparâmetros
best_params_df = pd.DataFrame(best_params_list, index=model_names)

# Exibir os melhores hiperparâmetros
print(best_params_df)

# Plotar as métricas de desempenho
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Model Performance Metrics')
results_df.plot(kind='bar', x='Model', y=['Mean Squared Error (MSE)', 'Root Mean Squared Error (RMSE)', 'R² (Coefficient of Determination)'], ax=plt.gca())
plt.xticks(rotation=45)
plt.tight_layout()

best_params_df

results_df

"""# **PCBN**"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt

# Carregar os dados
data = dados_PCBN  # Certifique-se de que a variável dados_CC6050W está definida e contém os dados
X = data.drop(['SPL', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['SPL']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir os parâmetros para o GridSearchCV
param_grid = {
    'linear_regression': {},
    'decision_tree': {
        'decision_tree__max_depth': [None, 10, 20, 30],
        'decision_tree__min_samples_split': [2, 5, 10],
        'decision_tree__min_samples_leaf': [1, 2, 4]
    },
    'random_forest': {
        'random_forest__n_estimators': [100, 200, 300],
        'random_forest__max_depth': [None, 10, 20, 30],
        'random_forest__min_samples_split': [2, 5, 10],
        'random_forest__min_samples_leaf': [1, 2, 4]
    },
    'mlp_regression': {
        'mlp_regression__hidden_layer_sizes': [(50,), (100,), (100, 50)],
        'mlp_regression__activation': ['tanh', 'relu'],
        'mlp_regression__solver': ['adam', 'sgd'],
        'mlp_regression__max_iter': [500, 1000]
    },
    'sgd_regression': {
        'sgd_regression__penalty': ['l2', 'l1', 'elasticnet'],
        'sgd_regression__alpha': [0.0001, 0.001, 0.01],
        'sgd_regression__max_iter': [1000, 2000]
    }
}

# Inicializar lista de pipelines
pipelines = {
    'linear_regression': Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    'decision_tree': Pipeline([('scaler', StandardScaler()), ('decision_tree', DecisionTreeRegressor())]),
    'random_forest': Pipeline([('scaler', StandardScaler()), ('random_forest', RandomForestRegressor())]),
    'mlp_regression': Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(random_state=42))]),
    'sgd_regression': Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(random_state=42))])
}

# Inicializar listas para armazenar os resultados
model_names = []
mse_values = []
rmse_values = []
r2_values = []
best_params_list = []

# Loop através dos pipelines
for model_name, pipeline in pipelines.items():
    # Configurar o GridSearchCV
    grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    grid_search.fit(X_train, y_train)

    # Obter o melhor modelo e os melhores hiperparâmetros
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_
    best_params_list.append(best_params)

    # Fazer previsões
    predictions = best_model.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, predictions)

    # Adicionar métricas à lista
    model_names.append(model_name)
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

# Criar dataframe com os melhores hiperparâmetros
best_params_df = pd.DataFrame(best_params_list, index=model_names)

# Exibir os melhores hiperparâmetros
print(best_params_df)

# Plotar as métricas de desempenho
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Model Performance Metrics')
results_df.plot(kind='bar', x='Model', y=['Mean Squared Error (MSE)', 'Root Mean Squared Error (RMSE)', 'R² (Coefficient of Determination)'], ax=plt.gca())
plt.xticks(rotation=45)
plt.tight_layout()

best_params_df

results_df

"""# **PREVISÕES**

# **CC6050W**

SOUND PRESSURE LEVEL
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt

# Carregar os dados
data = dados_CC6050W  # Certifique-se de que a variável dados_PCBN está definida e contém os dados
X = data.drop(['SPL', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['SPL']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir os parâmetros para o GridSearchCV
param_grid = {
    'linear_regression': {},
    'decision_tree': {
        'decision_tree__max_depth': [None, 10, 20, 30],
        'decision_tree__min_samples_split': [2, 5, 10],
        'decision_tree__min_samples_leaf': [1, 2, 4]
    },
    'random_forest': {
        'random_forest__n_estimators': [100, 200, 300],
        'random_forest__max_depth': [None, 10, 20, 30],
        'random_forest__min_samples_split': [2, 5, 10],
        'random_forest__min_samples_leaf': [1, 2, 4]
    },
    'mlp_regression': {
        'mlp_regression__hidden_layer_sizes': [(50,), (100,), (100, 50)],
        'mlp_regression__activation': ['tanh', 'relu'],
        'mlp_regression__solver': ['adam', 'sgd'],
        'mlp_regression__max_iter': [500, 1000]
    },
    'sgd_regression': {
        'sgd_regression__penalty': ['l2', 'l1', 'elasticnet'],
        'sgd_regression__alpha': [0.0001, 0.001, 0.01],
        'sgd_regression__max_iter': [1000, 2000]
    }
}

# Inicializar lista de pipelines
pipelines = {
    'linear_regression': Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    'decision_tree': Pipeline([('scaler', StandardScaler()), ('decision_tree', DecisionTreeRegressor())]),
    'random_forest': Pipeline([('scaler', StandardScaler()), ('random_forest', RandomForestRegressor())]),
    'mlp_regression': Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(random_state=42))]),
    'sgd_regression': Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(random_state=42))])
}

# Inicializar listas para armazenar os resultados
model_names = []
mse_values = []
rmse_values = []
r2_values = []
best_params_list = []
grid_searches = []

# Loop através dos pipelines
for model_name, pipeline in pipelines.items():
    # Configurar o GridSearchCV
    grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    grid_searches.append(grid_search)

    # Obter o melhor modelo e os melhores hiperparâmetros
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_
    best_params_list.append(best_params)

    # Fazer previsões
    predictions = best_model.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, predictions)

    # Adicionar métricas à lista
    model_names.append(model_name)
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

# Criar dataframe com os melhores hiperparâmetros
best_params_df = pd.DataFrame(best_params_list, index=model_names)

# Exibir os melhores hiperparâmetros
print(best_params_df)

# Dados para predição (coluna SPL removida)
prediction_data = pd.DataFrame({
    'Vc (mm)': [100.00, 225.00, 100.00, 225.00, 267.61, 162.50, 162.50, 162.50],
    'f (mm/rev)': [0.10, 0.10, 0.22, 0.22, 0.16, 0.05, 0.26, 0.16],
    'ap (mm)': [0.15, 0.15, 0.33, 0.33, 0.24, 0.24, 0.24, 0.09],
    'T': [62.00, 33.00, 52.00, 28.50, 24.50, 39.00, 40.25, 51.00]
})

# Valores reais de SPL
real_spl_values = [64.39, 83.26, 71.89, 87.52, 90.44, 83.15, 84.43, 80.27]

# Obter os melhores modelos do GridSearchCV
best_models = {model_name: grid_search.best_estimator_ for model_name, grid_search in zip(model_names, grid_searches)}

# Fazer previsões com os dados de predição
predictions = {}
for model_name, model in best_models.items():
    predictions[model_name] = model.predict(prediction_data)

# Criar um DataFrame para armazenar as previsões
prediction_df = pd.DataFrame(predictions)
prediction_df.index = prediction_data.index  # Alinhar os índices com prediction_data

# Exibir as previsões em formato de tabela
print("Predicted SPL Values:")
print(prediction_df)

# Calcular R² para cada modelo com base nos valores reais de SPL fornecidos
r2_real_values = {}
for model_name, predicted_values in predictions.items():
    r2_real_values[model_name] = r2_score(real_spl_values, predicted_values)

# Exibir R² para cada modelo
print("R² for each model based on real SPL values:")
for model_name, r2_value in r2_real_values.items():
    print(f"{model_name}: {r2_value}")

# Plotar os valores previstos e os valores reais em um único gráfico
plt.figure(figsize=(5, 3))
for model_name, predicted_values in predictions.items():
    plt.plot(prediction_data.index, predicted_values, label=model_name)
plt.plot(prediction_data.index, real_spl_values, label='Measured Values', color='black', linewidth=1.5, linestyle='--')
plt.title('Predicted SPL Values for Different Models - CC6050W')
plt.xlabel('Test Index')
plt.ylabel('Sound Pressure Level (SPL)')
plt.legend(loc='lower right', fontsize='10', handletextpad=0.5, labelspacing=0)
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt

# Carregar os dados
data = dados_CC6050W  # Certifique-se de que a variável dados_PCBN está definida e contém os dados
X = data.drop(['T', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['T']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir os parâmetros para o GridSearchCV
param_grid = {
    'linear_regression': {},
    'decision_tree': {
        'decision_tree__max_depth': [None, 10, 20, 30],
        'decision_tree__min_samples_split': [2, 5, 10],
        'decision_tree__min_samples_leaf': [1, 2, 4]
    },
    'random_forest': {
        'random_forest__n_estimators': [100, 200, 300],
        'random_forest__max_depth': [None, 10, 20, 30],
        'random_forest__min_samples_split': [2, 5, 10],
        'random_forest__min_samples_leaf': [1, 2, 4]
    },
    'mlp_regression': {
        'mlp_regression__hidden_layer_sizes': [(50,), (100,), (100, 50)],
        'mlp_regression__activation': ['tanh', 'relu'],
        'mlp_regression__solver': ['adam', 'sgd'],
        'mlp_regression__max_iter': [500, 1000]
    },
    'sgd_regression': {
        'sgd_regression__penalty': ['l2', 'l1', 'elasticnet'],
        'sgd_regression__alpha': [0.0001, 0.001, 0.01],
        'sgd_regression__max_iter': [1000, 2000]
    }
}

# Inicializar lista de pipelines
pipelines = {
    'linear_regression': Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    'decision_tree': Pipeline([('scaler', StandardScaler()), ('decision_tree', DecisionTreeRegressor())]),
    'random_forest': Pipeline([('scaler', StandardScaler()), ('random_forest', RandomForestRegressor())]),
    'mlp_regression': Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(random_state=42))]),
    'sgd_regression': Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(random_state=42))])
}

# Inicializar listas para armazenar os resultados
model_names = []
mse_values = []
rmse_values = []
r2_values = []
best_params_list = []
grid_searches = []

# Loop através dos pipelines
for model_name, pipeline in pipelines.items():
    # Configurar o GridSearchCV
    grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    grid_searches.append(grid_search)

    # Obter o melhor modelo e os melhores hiperparâmetros
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_
    best_params_list.append(best_params)

    # Fazer previsões
    predictions = best_model.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, predictions)

    # Adicionar métricas à lista
    model_names.append(model_name)
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

# Criar dataframe com os melhores hiperparâmetros
best_params_df = pd.DataFrame(best_params_list, index=model_names)

# Exibir os melhores hiperparâmetros
print(best_params_df)

# Dados para predição (coluna SPL removida)
prediction_data = pd.DataFrame({
    'Vc (mm)': [100.00, 225.00, 100.00, 225.00, 267.61, 162.50, 162.50, 162.50],
    'f (mm/rev)': [0.10, 0.10, 0.22, 0.22, 0.16, 0.05, 0.26, 0.16],
    'ap (mm)': [0.15, 0.15, 0.33, 0.33, 0.24, 0.24, 0.24, 0.09],
    'SPL': [64.39, 83.26, 69.49, 88.72, 95.44, 83.15, 85.53, 80.27]
})

# Valores reais de SPL
real_spl_values = [62.00, 33.00, 52.00, 28.50, 24.50, 39.00, 40.25, 51.00]

# Obter os melhores modelos do GridSearchCV
best_models = {model_name: grid_search.best_estimator_ for model_name, grid_search in zip(model_names, grid_searches)}

# Fazer previsões com os dados de predição
predictions = {}
for model_name, model in best_models.items():
    predictions[model_name] = model.predict(prediction_data)

# Criar um DataFrame para armazenar as previsões
prediction_df = pd.DataFrame(predictions)
prediction_df.index = prediction_data.index  # Alinhar os índices com prediction_data

# Exibir as previsões em formato de tabela
print("Predicted T Values:")
print(prediction_df)

# Calcular R² para cada modelo com base nos valores reais de SPL fornecidos
r2_real_values = {}
for model_name, predicted_values in predictions.items():
    r2_real_values[model_name] = r2_score(real_spl_values, predicted_values)

# Exibir R² para cada modelo
print("R² for each model based on real T values:")
for model_name, r2_value in r2_real_values.items():
    print(f"{model_name}: {r2_value}")

# Plotar os valores previstos e os valores reais em um único gráfico
plt.figure(figsize=(5, 3))
for model_name, predicted_values in predictions.items():
    plt.plot(prediction_data.index, predicted_values, label=model_name)
plt.plot(prediction_data.index, real_spl_values, label='Measured Values', color='black', linewidth=1.5, linestyle='--')
plt.title('Predicted T Values for Different Models - CC6050W')
plt.xlabel('Test Index')
plt.ylabel('Tool Life (T)')
plt.legend(loc='upper right', fontsize='10', handletextpad=0.5, labelspacing=0)
plt.show()

"""# **PCBN 7025W**"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt

# Carregar os dados
data = dados_PCBN  # Certifique-se de que a variável dados_PCBN está definida e contém os dados
X = data.drop(['SPL', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['SPL']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir os parâmetros para o GridSearchCV
param_grid = {
    'linear_regression': {},
    'decision_tree': {
        'decision_tree__max_depth': [None, 10, 20, 30],
        'decision_tree__min_samples_split': [2, 5, 10],
        'decision_tree__min_samples_leaf': [1, 2, 4]
    },
    'random_forest': {
        'random_forest__n_estimators': [100, 200, 300],
        'random_forest__max_depth': [None, 10, 20, 30],
        'random_forest__min_samples_split': [2, 5, 10],
        'random_forest__min_samples_leaf': [1, 2, 4]
    },
    'mlp_regression': {
        'mlp_regression__hidden_layer_sizes': [(50,), (100,), (100, 50)],
        'mlp_regression__activation': ['tanh', 'relu'],
        'mlp_regression__solver': ['adam', 'sgd'],
        'mlp_regression__max_iter': [500, 1000]
    },
    'sgd_regression': {
        'sgd_regression__penalty': ['l2', 'l1', 'elasticnet'],
        'sgd_regression__alpha': [0.0001, 0.001, 0.01],
        'sgd_regression__max_iter': [1000, 2000]
    }
}

# Inicializar lista de pipelines
pipelines = {
    'linear_regression': Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    'decision_tree': Pipeline([('scaler', StandardScaler()), ('decision_tree', DecisionTreeRegressor())]),
    'random_forest': Pipeline([('scaler', StandardScaler()), ('random_forest', RandomForestRegressor())]),
    'mlp_regression': Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(random_state=42))]),
    'sgd_regression': Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(random_state=42))])
}

# Inicializar listas para armazenar os resultados
model_names = []
mse_values = []
rmse_values = []
r2_values = []
best_params_list = []
grid_searches = []

# Loop através dos pipelines
for model_name, pipeline in pipelines.items():
    # Configurar o GridSearchCV
    grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    grid_searches.append(grid_search)

    # Obter o melhor modelo e os melhores hiperparâmetros
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_
    best_params_list.append(best_params)

    # Fazer previsões
    predictions = best_model.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, predictions)

    # Adicionar métricas à lista
    model_names.append(model_name)
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

# Criar dataframe com os melhores hiperparâmetros
best_params_df = pd.DataFrame(best_params_list, index=model_names)

# Exibir os melhores hiperparâmetros
print(best_params_df)

# Dados para predição (coluna SPL removida)
prediction_data = pd.DataFrame({
    'Vc (mm)': [100.00, 225.00, 100.00, 225.00, 267.61, 162.50, 162.50, 162.50],
    'f (mm/rev)': [0.10, 0.10, 0.22, 0.22, 0.16, 0.05, 0.26, 0.16],
    'ap (mm)': [0.15, 0.15, 0.33, 0.33, 0.24, 0.24, 0.24, 0.09],
    'T': [70.00, 35.00, 55.00, 31.50, 28.25, 42.50, 44.50, 54.50]
})

# Valores reais de SPL
real_spl_values = [65.50, 88.30, 73.54, 90.50, 93.79, 82.34, 83.46, 82.41]

# Obter os melhores modelos do GridSearchCV
best_models = {model_name: grid_search.best_estimator_ for model_name, grid_search in zip(model_names, grid_searches)}

# Fazer previsões com os dados de predição
predictions = {}
for model_name, model in best_models.items():
    predictions[model_name] = model.predict(prediction_data)

# Criar um DataFrame para armazenar as previsões
prediction_df = pd.DataFrame(predictions)
prediction_df.index = prediction_data.index  # Alinhar os índices com prediction_data

# Exibir as previsões em formato de tabela
print("Predicted SPL Values:")
print(prediction_df)

# Calcular R² para cada modelo com base nos valores reais de SPL fornecidos
r2_real_values = {}
for model_name, predicted_values in predictions.items():
    r2_real_values[model_name] = r2_score(real_spl_values, predicted_values)

# Exibir R² para cada modelo
print("R² for each model based on real SPL values:")
for model_name, r2_value in r2_real_values.items():
    print(f"{model_name}: {r2_value}")

# Plotar os valores previstos e os valores reais em um único gráfico
plt.figure(figsize=(5, 3))
for model_name, predicted_values in predictions.items():
    plt.plot(prediction_data.index, predicted_values, label=model_name)
plt.plot(prediction_data.index, real_spl_values, label='Measured Values', color='black', linewidth=1.5, linestyle='--')
plt.title('Predicted SPL Values for Different Models - PCBN 7025W')
plt.xlabel('Test Index')
plt.ylabel('Sound Pressure Level (SPL)')
plt.legend(loc='lower right', fontsize='10', handletextpad=0.5, labelspacing=0)
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import matplotlib.pyplot as plt

# Carregar os dados
data = dados_PCBN  # Certifique-se de que a variável dados_PCBN está definida e contém os dados
X = data.drop(['T', 'Tool'], axis=1)  # Características (excluindo a variável de saída)
y = data['T']  # Variável de saída

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir os parâmetros para o GridSearchCV
param_grid = {
    'linear_regression': {},
    'decision_tree': {
        'decision_tree__max_depth': [None, 10, 20, 30],
        'decision_tree__min_samples_split': [2, 5, 10],
        'decision_tree__min_samples_leaf': [1, 2, 4]
    },
    'random_forest': {
        'random_forest__n_estimators': [100, 200, 300],
        'random_forest__max_depth': [None, 10, 20, 30],
        'random_forest__min_samples_split': [2, 5, 10],
        'random_forest__min_samples_leaf': [1, 2, 4]
    },
    'mlp_regression': {
        'mlp_regression__hidden_layer_sizes': [(50,), (100,), (100, 50)],
        'mlp_regression__activation': ['tanh', 'relu'],
        'mlp_regression__solver': ['adam', 'sgd'],
        'mlp_regression__max_iter': [500, 1000]
    },
    'sgd_regression': {
        'sgd_regression__penalty': ['l2', 'l1', 'elasticnet'],
        'sgd_regression__alpha': [0.0001, 0.001, 0.01],
        'sgd_regression__max_iter': [1000, 2000]
    }
}

# Inicializar lista de pipelines
pipelines = {
    'linear_regression': Pipeline([('scaler', StandardScaler()), ('linear_regression', LinearRegression())]),
    'decision_tree': Pipeline([('scaler', StandardScaler()), ('decision_tree', DecisionTreeRegressor())]),
    'random_forest': Pipeline([('scaler', StandardScaler()), ('random_forest', RandomForestRegressor())]),
    'mlp_regression': Pipeline([('scaler', StandardScaler()), ('mlp_regression', MLPRegressor(random_state=42))]),
    'sgd_regression': Pipeline([('scaler', StandardScaler()), ('sgd_regression', SGDRegressor(random_state=42))])
}

# Inicializar listas para armazenar os resultados
model_names = []
mse_values = []
rmse_values = []
r2_values = []
best_params_list = []
grid_searches = []

# Loop através dos pipelines
for model_name, pipeline in pipelines.items():
    # Configurar o GridSearchCV
    grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    grid_searches.append(grid_search)

    # Obter o melhor modelo e os melhores hiperparâmetros
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_
    best_params_list.append(best_params)

    # Fazer previsões
    predictions = best_model.predict(X_test)

    # Calcular métricas
    mse = mean_squared_error(y_test, predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, predictions)

    # Adicionar métricas à lista
    model_names.append(model_name)
    mse_values.append(mse)
    rmse_values.append(rmse)
    r2_values.append(r2)

# Criar dataframe com os resultados
results_df = pd.DataFrame({
    'Model': model_names,
    'Mean Squared Error (MSE)': mse_values,
    'Root Mean Squared Error (RMSE)': rmse_values,
    'R² (Coefficient of Determination)': r2_values
})

# Exibir os resultados
print(results_df)

# Criar dataframe com os melhores hiperparâmetros
best_params_df = pd.DataFrame(best_params_list, index=model_names)

# Exibir os melhores hiperparâmetros
print(best_params_df)

# Dados para predição (coluna SPL removida)
prediction_data = pd.DataFrame({
    'Vc (mm)': [100.00, 225.00, 100.00, 225.00, 267.61, 162.50, 162.50, 162.50],
    'f (mm/rev)': [0.10, 0.10, 0.22, 0.22, 0.16, 0.05, 0.26, 0.16],
    'ap (mm)': [0.15, 0.15, 0.33, 0.33, 0.24, 0.24, 0.24, 0.09],
    'SPL': [65.50, 88.30, 77.54, 90.50, 93.79, 82.34, 83.46, 82.41]
})

# Valores reais de SPL
real_spl_values = [70.00, 35.00, 55.00, 31.50, 28.25, 42.50, 44.50, 54.50]

# Obter os melhores modelos do GridSearchCV
best_models = {model_name: grid_search.best_estimator_ for model_name, grid_search in zip(model_names, grid_searches)}

# Fazer previsões com os dados de predição
predictions = {}
for model_name, model in best_models.items():
    predictions[model_name] = model.predict(prediction_data)

# Criar um DataFrame para armazenar as previsões
prediction_df = pd.DataFrame(predictions)
prediction_df.index = prediction_data.index  # Alinhar os índices com prediction_data

# Exibir as previsões em formato de tabela
print("Predicted SPL Values:")
print(prediction_df)

# Calcular R² para cada modelo com base nos valores reais de SPL fornecidos
r2_real_values = {}
for model_name, predicted_values in predictions.items():
    r2_real_values[model_name] = r2_score(real_spl_values, predicted_values)

# Exibir R² para cada modelo
print("R² for each model based on real T values:")
for model_name, r2_value in r2_real_values.items():
    print(f"{model_name}: {r2_value}")

# Plotar os valores previstos e os valores reais em um único gráfico
plt.figure(figsize=(5, 3))
for model_name, predicted_values in predictions.items():
    plt.plot(prediction_data.index, predicted_values, label=model_name)
plt.plot(prediction_data.index, real_spl_values, label='Measured Values', color='black', linewidth=1.5, linestyle='--')
plt.title('Predicted T Values for Different Models - PCBN 7025W')
plt.xlabel('Test Index')
plt.ylabel('Tool Life (T)')
plt.legend(loc='upper right', fontsize='10', handletextpad=0.5, labelspacing=0)
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Data from the table
models = ['Linear\nRegression', 'Decision\nTree', 'Random\nForest', 'MLP\nRegression', 'SGD\nRegression']
t_cc6050w = [0.8891, 0.9497, 0.9523, 0.9334, 0.8794]
t_pcbn_7025 = [0.8871, 0.7105, 0.8730, 0.9399, 0.8930]
spl_cc6050w = [0.5926, 0.8399, 0.8530, 0.1349, 0.6173]
spl_pcbn_7025 = [0.8685, 0.8702, 0.9032, 0.5229, 0.8788]

x = np.arange(len(models))

# Plotting R² values for T
fig, ax = plt.subplots(2, 1, figsize=(6, 5))

# Common y-axis limits and ticks
y_ticks = np.arange(0, 1.25, 0.25)

# T values
ax[0].bar(x - 0.2, t_cc6050w, 0.4, label='T - CC6050W')
ax[0].bar(x + 0.2, t_pcbn_7025, 0.4, label='T - PCBN 7025')
ax[0].set_xticks(x)
ax[0].set_xticklabels(models, rotation=0, ha='center', fontsize=10)
ax[0].set_yticks(y_ticks)
ax[0].set_yticklabels(y_ticks, fontsize=10)
ax[0].set_ylabel('R² Value', fontsize=10)
ax[0].set_title('R² Values for Tool Life (T)', fontsize=12)
ax[0].set_ylim(0, 1)
ax[0].grid(axis='y')

# SPL values
ax[1].bar(x - 0.2, spl_cc6050w, 0.4, label='SPL - CC6050W')
ax[1].bar(x + 0.2, spl_pcbn_7025, 0.4, label='SPL - PCBN 7025')
ax[1].set_xticks(x)
ax[1].set_xticklabels(models, rotation=0, ha='center', fontsize=10)
ax[1].set_yticks(y_ticks)
ax[1].set_yticklabels(y_ticks, fontsize=10)
ax[1].set_ylabel('R² Value', fontsize=10)
ax[1].set_title('R² Values for Sound Pressure Level (SPL)', fontsize=12)
ax[1].set_ylim(0, 1)
ax[1].grid(axis='y')

# Add a single legend below the second graph
fig.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=4, fontsize=10)

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Data from the table
models = ['Linear\nRegression', 'Decision\nTree', 'Random\nForest', 'MLP\nRegression', 'SGD\nRegression']
t_cc6050w = [0.8791, 0.9497, 0.9523, 0.9334, 0.8794]
t_pcbn_7025 = [0.8871, 0.7105, 0.8730, 0.9399, 0.8930]
spl_cc6050w = [0.5926, 0.8399, 0.8530, 0.1349, 0.6173]
spl_pcbn_7025 = [0.8685, 0.8702, 0.9032, 0.5229, 0.8788]

x = np.arange(len(models))

# Plotting R² values for T
fig, ax = plt.subplots(2, 1, figsize=(5, 6))

# Common y-axis limits and ticks
y_ticks = np.arange(0, 1.25, 0.25)

# T values
ax[0].bar(x - 0.2, t_cc6050w, 0.4, label='CC6050W')
ax[0].bar(x + 0.2, t_pcbn_7025, 0.4, label='PCBN 7025')
for i in range(len(x)):
    ax[0].text(x[i] - 0.2, t_cc6050w[i] + 0.02, f'{t_cc6050w[i]:.2f}', ha='center', fontsize=10)
    ax[0].text(x[i] + 0.2, t_pcbn_7025[i] + 0.02, f'{t_pcbn_7025[i]:.2f}', ha='center', fontsize=10)
ax[0].set_xticks(x)
ax[0].set_xticklabels(models, rotation=0, ha='center', fontsize=12)
ax[0].set_yticks(y_ticks)
ax[0].set_yticklabels(y_ticks, fontsize=12)
ax[0].set_ylabel('R² Value', fontsize=12)
ax[0].set_title('R² Values for Tool Life (T)', fontsize=12)
ax[0].set_ylim(0, 1.05)
#ax[0].grid(axis='y')

# SPL values
ax[1].bar(x - 0.2, spl_cc6050w, 0.4, label='CC6050W')
ax[1].bar(x + 0.2, spl_pcbn_7025, 0.4, label='PCBN 7025')
for i in range(len(x)):
    ax[1].text(x[i] - 0.2, spl_cc6050w[i] + 0.02, f'{spl_cc6050w[i]:.2f}', ha='center', fontsize=10)
    ax[1].text(x[i] + 0.2, spl_pcbn_7025[i] + 0.02, f'{spl_pcbn_7025[i]:.2f}', ha='center', fontsize=10)
ax[1].set_xticks(x)
ax[1].set_xticklabels(models, rotation=0, ha='center', fontsize=12)
ax[1].set_yticks(y_ticks)
ax[1].set_yticklabels(y_ticks, fontsize=12)
ax[1].set_ylabel('R² Value', fontsize=12)
ax[1].set_title('R² Values for Sound Pressure Level (SPL)', fontsize=12)
ax[1].set_ylim(0, 1.05)
#ax[1].grid(axis='y')

# Add a single legend below the second graph
fig.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=2, fontsize=10, labelspacing=0)

plt.tight_layout()
plt.show()